{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "from langchain.schema import Document\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.vectorstores import Chroma \n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import chromadb\n",
    "from groq import Groq\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentLoader:\n",
    "    @staticmethod\n",
    "    def load_docs(file_paths: List[str]) -> List[Document]:\n",
    "        \"\"\"\n",
    "        ໂຫລດ PDF documents ໂດຍໃຊ້ LangChain PyPDFLoader ເພາະຍັງແອັດຈັງມັກເພາະມັນສ້າງ Metadata ໃຫ້ Auto \n",
    "\n",
    "        Metadata ຄືຍັງ ? \n",
    "        Metadata ຄືຂໍ້ມູນເພີ່ມເຕີມກ່ຽວກັບເອກະສານ\n",
    "        ແຕ່ລະ Document ຈະມີ 2 ສ່ວນຫຼັກ:\n",
    "        1. page_content: ເນື້ອໃນຂໍ້ຄວາມຈິງໆ\n",
    "        2. metadata: ຂໍ້ມູນລາຍລະອຽດກ່ຽວກັບເອກະສານ ເພື່ອບົງບອກວ່າ ເວລາເຮົາ ຄົ້ນຫາຂໍ້ມູນ ແຫຼ່ງຂໍ້ມູນນັ້ນມາຈາກໄສ\n",
    "        \n",
    "        Args:\n",
    "            file_paths (list): List of PDF file paths\n",
    "        \n",
    "        Returns:\n",
    "            List[Document]: List of LangChain Document objects\n",
    "        \"\"\"\n",
    "        \n",
    "        all_docs = []\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"Warning: File {file_path} not found. Skipping...\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                file_extension = os.path.splitext(file_path)[1].lower()\n",
    "                \n",
    "                # Check if file is PDF\n",
    "                if file_extension != '.pdf':\n",
    "                    print(f\"Warning: {file_path} is not a PDF file. Skipping...\")\n",
    "                    continue\n",
    "                \n",
    "                # Load PDF using LangChain PyPDFLoader\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                # Add enhanced metadata to all documents\n",
    "                for doc in documents:\n",
    "                    if doc.metadata is None:\n",
    "                        doc.metadata = {}\n",
    "                        \n",
    "                    doc.metadata.update({\n",
    "                        'source_file': os.path.basename(file_path),\n",
    "                        'file_type': file_extension,\n",
    "                        'file_path': file_path,\n",
    "                        'file_size': os.path.getsize(file_path) if os.path.exists(file_path) else 0,\n",
    "                    })\n",
    "                \n",
    "                all_docs.extend(documents)\n",
    "                print(f\"✅ Processed PDF: {file_path} ({len(documents)} pages)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error processing {file_path}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"📚 Total PDF documents loaded: {len(all_docs)}\")\n",
    "        return all_docs\n",
    "    \n",
    "    @staticmethod\n",
    "    def chunk_documents_standard(\n",
    "        docs: List[Document], \n",
    "        chunk_size: int = 1000,\n",
    "        chunk_overlap: int = 200,\n",
    "        tokenizer_model: str = \"D:/model/BAAI-bge-m3\",\n",
    "        max_token_limit: int = 8192\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"\n",
    "        ໃຊ້ Lanchain ໃນການເຮັດ chunking ຂໍ້ມູນ ເພື່ອການຄົ້ນຫາຂໍ້ມູນດ້ວຍ ChromaDB  \n",
    "\n",
    "        Chunk_size: ແມ່ນຈຳນວນຂໍ້ມູນທີ່ຈະເຮັດ chunking ຕໍ່ຫນ່ວຍ ເພາະຍັງ ເຮົາບໍ່ສາມາດເອົາເອກະສານທັ້ງໝົດໃຫ້ AI ຕອບໄດ້ ເນື່ອງຈາກບາງເອກະສານມີຫລາຍຫນ້າ\n",
    "        Chunk_overlap: ແມ່ນຈຳນວນຂໍ້ມູນທີ່ຈະເຮັດ chunking ຕໍ່ຫນ່ວຍ ເພາະຍັງ ເຮົາບໍ່ສາມາດເອົາເອກະສານທັ້ງໝົດໃຫ້ AI ຕອບໄດ້ ເນື່ອງຈາກບາງເອກະສານມີຫລາຍຫນ້າ\n",
    "        Tokenizer_model: ແມ່ນ Model ທີ່ເຮົາຈະໃຊ້ໃນການເຮັດ chunking ຂໍ້ມູນ ເພື່ອການຄົ້ນຫາຂໍ້ມູນດ້ວຍ ChromaDB\n",
    "        Max_token_limit: ແມ່ນການແບ່ງສັດສ່ວນໃຫ້ເຫມາະສົມກັບ chunk_size\n",
    "        \n",
    "        Args:\n",
    "            docs: List of LangChain Document objects\n",
    "            chunk_size: Target size for each chunk in tokens\n",
    "            chunk_overlap: Number of overlapping tokens between chunks\n",
    "            tokenizer_model: Path to tokenizer model\n",
    "            max_token_limit: Maximum tokens allowed\n",
    "            \n",
    "        Returns:\n",
    "            List of chunked LangChain Document objects\n",
    "        \"\"\"\n",
    "        \n",
    "        if not docs:\n",
    "            print(\"⚠️  No documents provided for chunking\")\n",
    "            return []\n",
    "        \n",
    "        # Load tokenizer\n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(tokenizer_model)\n",
    "            print(f\"✅ Loaded tokenizer: {tokenizer_model}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading tokenizer: {e}\") \n",
    "        \n",
    "        # Validate parameters\n",
    "        if chunk_size >= max_token_limit:\n",
    "            chunk_size = max_token_limit - 500  # Safe buffer\n",
    "            print(f\"⚠️  Adjusted chunk_size to {chunk_size} for safety\")\n",
    "        \n",
    "        if chunk_overlap >= chunk_size:\n",
    "            chunk_overlap = chunk_size // 5  # 20% overlap\n",
    "            print(f\"⚠️  Adjusted chunk_overlap to {chunk_overlap}\")\n",
    "        \n",
    "        # Create tokenizer-aware text splitter\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "            tokenizer=tokenizer,\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            strip_whitespace=True,\n",
    "            separators=[\n",
    "                \"\\n\\n\",      # Paragraph breaks\n",
    "                \"\\n\",        # Line breaks\n",
    "                \". \",        # Sentence endings\n",
    "                \"! \",        # Exclamation endings  \n",
    "                \"? \",        # Question endings\n",
    "                \"; \",        # Semicolon breaks\n",
    "                \", \",        # Comma breaks\n",
    "                \" \",         # Word breaks\n",
    "                \"\"           # Character level\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Split documents\n",
    "        print(f\"🔄 Chunking {len(docs)} documents...\")\n",
    "        chunked_docs = text_splitter.split_documents(docs)\n",
    "        \n",
    "        # Validate token counts and add metadata\n",
    "        validated_chunks = []\n",
    "        max_tokens_found = 0\n",
    "        \n",
    "        for i, chunk in enumerate(chunked_docs):\n",
    "            # Count actual tokens\n",
    "            token_count = len(tokenizer.encode(chunk.page_content))\n",
    "            max_tokens_found = max(max_tokens_found, token_count)\n",
    "            \n",
    "            # Add chunk metadata\n",
    "            if chunk.metadata is None:\n",
    "                chunk.metadata = {}\n",
    "                \n",
    "            chunk.metadata.update({\n",
    "                'chunk_id': i,\n",
    "                'token_count': token_count,\n",
    "                'char_count': len(chunk.page_content),\n",
    "                'chunk_method': 'tokenizer_based'\n",
    "            })\n",
    "            \n",
    "            # Skip if too large\n",
    "            if token_count > max_token_limit:\n",
    "                print(f\"⚠️  Skipping oversized chunk {i}: {token_count} tokens\")\n",
    "                continue\n",
    "                \n",
    "            validated_chunks.append(chunk)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"✅ Created {len(validated_chunks)} chunks\")\n",
    "        print(f\"📊 Max tokens in any chunk: {max_tokens_found}\")\n",
    "        \n",
    "        return validated_chunks\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_vector_store(\n",
    "        chunked_docs: List[Document],\n",
    "        embedding_model: str = \"D:/model/BAAI-bge-m3\",\n",
    "        collection_name: str = \"pdf_documents\",\n",
    "        persist_directory: str = \"./chroma_db\",\n",
    "        batch_size: int = 50\n",
    "    ) -> Chroma:\n",
    "        \"\"\"\n",
    "        ສ້າງ Vector Store ດ້ວຍ ChromaDB ຈາກ chunked documents\n",
    "        \n",
    "        Embedding_model: ແມ່ນ Model ທີ່ໃຊ້ໃນການເຮັດ Embedding ເພື່ອປ່ຽນຂໍ້ຄວາມເປັນ Vector\n",
    "        Collection_name: ແມ່ນຊື່ຂອງ Collection ໃນ ChromaDB ສາມາດສ້າງຕາມໃຈ ທີ່ຕ້ອງການ ແນະນຳໃຫ້ສ້າງເປັນ Folder ຂອງໃຜມັນ ແລະ point ໄປ Folder ນັ່ນ ເພາະວ່າ ChromaDB ເວລາມັນບັນທືກມັນຈະບັນທືກ unique key ເຊີ່ງມັນຈະເຮັດໃຫ້ເຮົາຈຳແນກຢາກ\n",
    "        Persist_directory: ແມ່ນໂຟລເດີຢຸ້ບັນທຶກ ChromaDB\n",
    "        Batch_size: ແມ່ນຈຳນວນ chunks ທີ່ເຮັດ embedding ຕໍ່ຄັ້ງ ເພື່ອປ້ອງກັນ memory overflow\n",
    "        \n",
    "        Args:\n",
    "            chunked_docs: List of chunked Document objects\n",
    "            embedding_model: Path to embedding model\n",
    "            collection_name: Name for ChromaDB collection\n",
    "            persist_directory: Directory to save ChromaDB\n",
    "            batch_size: Number of documents to process at once\n",
    "            \n",
    "        Returns:\n",
    "            Chroma vector store object\n",
    "        \"\"\"\n",
    "        \n",
    "        if not chunked_docs:\n",
    "            print(\"⚠️  No chunked documents provided\")\n",
    "            return None\n",
    "        \n",
    "        # Create embeddings\n",
    "        try:\n",
    "            print(f\"🔄 Loading embedding model: {embedding_model}\")\n",
    "            embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=embedding_model,\n",
    "                model_kwargs={'device': 'cpu'},  # ປ່ຽນເປັນ 'cuda' ຖ້າມີ GPU\n",
    "                encode_kwargs={'normalize_embeddings': True}\n",
    "            )\n",
    "            print(f\"✅ Loaded embedding model successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading embedding model: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # Create ChromaDB client and collection\n",
    "        try:\n",
    "            # ສ້າງໂຟລເດີຖ້າຍັງບໍ່ມີ\n",
    "            os.makedirs(persist_directory, exist_ok=True)\n",
    "            \n",
    "            print(f\"🔄 Creating ChromaDB collection: {collection_name}\")\n",
    "            \n",
    "            # ລືບ collection ເກົ່າຖ້າມີ (ປ້ອງກັນຂໍ້ຜິດພາດ)\n",
    "            try:\n",
    "                client = chromadb.PersistentClient(path=persist_directory)\n",
    "                try:\n",
    "                    client.delete_collection(collection_name)\n",
    "                    print(f\"🗑️  Deleted existing collection: {collection_name}\")\n",
    "                except:\n",
    "                    pass  # Collection ບໍ່ມີຢູ່ແລ້ວ\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Warning during cleanup: {e}\")\n",
    "            \n",
    "            # ສ້າງ vector store ແບບ batch\n",
    "            print(f\"🔄 Processing {len(chunked_docs)} documents in batches of {batch_size}\")\n",
    "            \n",
    "            vector_store = None\n",
    "            total_processed = 0\n",
    "            \n",
    "            for i in range(0, len(chunked_docs), batch_size):\n",
    "                batch = chunked_docs[i:i + batch_size]\n",
    "                batch_num = (i // batch_size) + 1\n",
    "                total_batches = (len(chunked_docs) + batch_size - 1) // batch_size\n",
    "                \n",
    "                print(f\"📦 Processing batch {batch_num}/{total_batches} ({len(batch)} documents)\")\n",
    "                \n",
    "                try:\n",
    "                    if vector_store is None:\n",
    "                        # ສ້າງ vector store ທຳອິດ\n",
    "                        vector_store = Chroma.from_documents(\n",
    "                            documents=batch,\n",
    "                            embedding=embeddings,\n",
    "                            collection_name=collection_name,\n",
    "                            persist_directory=persist_directory\n",
    "                        )\n",
    "                    else:\n",
    "                        # ເພີ່ມ documents ໃໝ່ເຂົ້າໄປ\n",
    "                        vector_store.add_documents(batch)\n",
    "                    \n",
    "                    total_processed += len(batch)\n",
    "                    print(f\"✅ Batch {batch_num} completed. Total processed: {total_processed}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error processing batch {batch_num}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # ບັນທຶກການປ່ຽນແປງ\n",
    "            if vector_store:\n",
    "                vector_store.persist()\n",
    "                print(f\"💾 Vector store saved to: {persist_directory}\")\n",
    "                \n",
    "                collection_count = vector_store._collection.count()\n",
    "                print(f\"📊 Total vectors in collection: {collection_count}\")\n",
    "                print(f\"📚 Collection name: {collection_name}\")\n",
    "                \n",
    "                return vector_store\n",
    "            else:\n",
    "                print(\"❌ Failed to create vector store\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error creating vector store: {e}\")\n",
    "            return None\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_existing_vector_store(\n",
    "        embedding_model: str = \"D:/model/BAAI-bge-m3\",\n",
    "        collection_name: str = \"pdf_documents\", \n",
    "        persist_directory: str = \"./chroma_db\"\n",
    "    ) -> Optional[Chroma]:\n",
    "        \"\"\"\n",
    "        ໂຫຼດ Vector Store ທີ່ມີຢູ່ແລ້ວຈາກ ChromaDB\n",
    "        \n",
    "        Args:\n",
    "            embedding_model: Path to embedding model\n",
    "            collection_name: Name of ChromaDB collection\n",
    "            persist_directory: Directory where ChromaDB is saved\n",
    "            \n",
    "        Returns:\n",
    "            Chroma vector store object or None\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            # ກວດສອບວ່າມີໂຟລເດີຫຼືບໍ່\n",
    "            if not os.path.exists(persist_directory):\n",
    "                print(f\"❌ Directory not found: {persist_directory}\")\n",
    "                return None\n",
    "            \n",
    "            # ໂຫຼດ embedding model\n",
    "            embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=embedding_model,\n",
    "                model_kwargs={'device': 'cpu'},\n",
    "                encode_kwargs={'normalize_embeddings': True}\n",
    "            )\n",
    "            \n",
    "            # ໂຫຼດ vector store\n",
    "            vector_store = Chroma(\n",
    "                collection_name=collection_name,\n",
    "                embedding_function=embeddings,\n",
    "                persist_directory=persist_directory\n",
    "            )\n",
    "            \n",
    "            # ກວດສອບວ່າມີຂໍ້ມູນຫຼືບໍ່\n",
    "            collection_count = vector_store._collection.count()\n",
    "            if collection_count > 0:\n",
    "                print(f\"✅ Loaded existing vector store: {collection_name}\")\n",
    "                print(f\"📊 Total vectors: {collection_count}\")\n",
    "                return vector_store\n",
    "            else:\n",
    "                print(f\"⚠️  Collection '{collection_name}' is empty\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading vector store: {e}\")\n",
    "            return None\n",
    "        \n",
    "    @staticmethod\n",
    "    def search_similar_documents(\n",
    "        vector_store: Chroma,\n",
    "        query: str,\n",
    "        k: int = 5\n",
    "    ) -> List[tuple]:\n",
    "        \"\"\"\n",
    "        ຄົ້ນຫາເອກະສານທີ່ຄ້າຍຄືກັນ\n",
    "        vector_store: ແມ່ນຂໍ້ມູເຮົາເຄີຍສ້າງ Vector Store ໃນ ./chroma_db\n",
    "        query: ຄຳຖາມທີ່ຕ້ອງການຄົ້ນຫາ\n",
    "        k: ຈຳນວນຜົນລັບທີ່ຕ້ອງການ\n",
    "            \n",
    "        Returns:\n",
    "            List of tuples (document, score)\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"🔍 Searching for: {query}\")\n",
    "            \n",
    "            # ຄົ້ນຫາດ້ວຍ score\n",
    "            results = vector_store.similarity_search_with_score(\n",
    "                query=query,\n",
    "                k=k\n",
    "            )\n",
    "            \n",
    "            # ສະແດງຜົນລັບ\n",
    "            # for i, (doc, score) in enumerate(results):\n",
    "            #     similarity = 1 - score  # ປ່ຽນ distance ເປັນ similarity\n",
    "            #     print(f\"\\n📄 Result {i+1} (Similarity: {similarity:.3f}):\")\n",
    "            #     print(f\"   📁 Source: {doc.metadata.get('source_file', 'Unknown')}\")\n",
    "            #     print(f\"   📄 Page: {doc.metadata.get('page', 'Unknown')}\")\n",
    "            #     print(f\"   🔖 Chunk: {doc.metadata.get('chunk_id', 'Unknown')}\")\n",
    "            #     print(f\"   📝 Content preview: {doc.page_content[:100]}...\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error during search: {e}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroqRAGSystem:\n",
    "    \"\"\"\n",
    "    ລະບົບ RAG ປະສົມກັບ Groq LLM ເພື່ອຕອບຄຳຖາມອ້າງອີງຈາກເອກະສານ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, groq_api_key: str, model_name: str = \"openai/gpt-oss-120b\"):\n",
    "        \"\"\"\n",
    "        ເລີ່ມຕົ້ນ GroqRAGSystem\n",
    "        \n",
    "        Args:\n",
    "            groq_api_key: Groq API key (ຕ້ອງໄປສະໝັກທີ່ https://console.groq.com)\n",
    "            model_name: ຊື່ Model ທີ່ຈະໃຊ້ (ຍົກຕົວຢ່າງ: openai/gpt-oss-120b)\n",
    "        \"\"\"\n",
    "        self.client = Groq(api_key=groq_api_key)\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def create_context_from_documents(self, search_results: List[tuple]) -> str:\n",
    "        \"\"\"\n",
    "        ສ້າງ context ຈາກຜົນການຄົ້ນຫາເອກະສານ\n",
    "        \n",
    "        Args:\n",
    "            search_results: List of tuples (document, score) ຈາກ vector search\n",
    "            \n",
    "        Returns:\n",
    "            ຂໍ້ຄວາມ context ສຳລັບ LLM\n",
    "        \"\"\"\n",
    "        if not search_results:\n",
    "            return \"ບໍ່ພົບເອກະສານທີ່ກ່ຽວຂ້ອງ\"\n",
    "            \n",
    "        context_parts = []\n",
    "        for i, (doc, score) in enumerate(search_results):\n",
    "            similarity = 1 - score\n",
    "            source_info = f\"ແຫຼ່ງ: {doc.metadata.get('source_file', 'Unknown')} (ໜ້າ {doc.metadata.get('page', 'Unknown')})\"\n",
    "            content = doc.page_content.strip()\n",
    "            \n",
    "            context_parts.append(f\"ເອກະສານ {i+1} (ຄວາມຄ້າຍຄື: {similarity:.3f}):\\n{source_info}\\n{content}\\n\")\n",
    "            \n",
    "        return \"\\n---\\n\".join(context_parts)\n",
    "    \n",
    "    def generate_answer(self, query: str, context: str) -> str:\n",
    "        \"\"\"\n",
    "        ສ້າງຄຳຕອບໂດຍໃຊ້ Groq LLM ພ້ອມ context ຈາກເອກະສານ\n",
    "        \n",
    "        Args:\n",
    "            query: ຄຳຖາມຂອງຜູ້ໃຊ້\n",
    "            context: Context ຈາກເອກະສານ\n",
    "            \n",
    "        Returns:\n",
    "            ຄຳຕອບຈາກ LLM\n",
    "        \"\"\"\n",
    "        \n",
    "        # ສ້າງ prompt ສຳລັບ RAG\n",
    "        prompt = f\"\"\"ທ່ານເປັນ AI Assistant ທີ່ຊ່ຽວຊານໃນການຕອບຄຳຖາມໂດຍອ້າງອີງຈາກເອກະສານທີ່ໃຫ້ມາ.\n",
    "\n",
    "ຄຳແນະນຳ:\n",
    "1. ຕອບຄຳຖາມໂດຍອ້າງອີງຈາກເອກະສານທີ່ໃຫ້ມາເທົ່ານັ້ນ\n",
    "2. ຖ້າບໍ່ພົບຄຳຕອບໃນເອກະສານ, ໃຫ້ບອກວ່າບໍ່ພົບຂໍ້ມູນທີ່ກ່ຽວຂ້ອງ\n",
    "3. ລະບຸແຫຼ່ງຂໍ້ມູນທີ່ໃຊ້ໃນການຕອບ\n",
    "4. ຕອບເປັນພາສາລາວ ແລະ ໃຫ້ຄຳຕອບທີ່ຊັດເຈນ, ລະອຽດ\n",
    "5. ຕອບໃຫ້ເປັນ Format markdown\n",
    "\n",
    "ເອກະສານອ້າງອີງ:\n",
    "{context}\n",
    "\n",
    "ຄຳຖາມ: {query}\n",
    "\n",
    "ຄຳຕອບ:\"\"\"\n",
    "\n",
    "        try:\n",
    "            # ສົ່ງ request ໄປ Groq\n",
    "            chat_completion = self.client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                model=self.model_name,\n",
    "                temperature=0.1,  # ຄວາມສ້າງສັນຕ່ຳ ເພື່ອຄວາມແມ່ນຍຳ  ຂຶ້ນນຳ Model ເພາະຄ່າ temperature ແຕ່ລະເຈົ້າມັນຕ່າງກັນ\n",
    "                max_tokens=2000,  # ຈຳນວນ tokens ສູງສຸດ \n",
    "            )\n",
    "            \n",
    "            answer = chat_completion.choices[0].message.content\n",
    "            return answer\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"❌ ເກີດຂໍ້ຜິດພາດໃນການສ້າງຄຳຕອບ: {str(e)}\"\n",
    "    \n",
    "    def query_documents(self, vector_store: Chroma, query: str, k: int = 5) -> dict:\n",
    "        \"\"\"\n",
    "        ຄຳຖາມແບບສົມບູນຈາກການຄົ້ນຫາເອກະສານຈົນເຖີງການສ້າງຄຳຕອບ\n",
    "        \n",
    "        Args:\n",
    "            vector_store: ChromaDB vector store\n",
    "            query: ຄຳຖາມຂອງຜູ້ໃຊ້\n",
    "            k: ຈຳນວນເອກະສານທີ່ຈະຄົ້ນຫາ\n",
    "            \n",
    "        Returns:\n",
    "            dict ທີ່ປະກອບດ້ວຍ answer, context, ແລະ sources\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"\\n🤖 Processing query: {query}\")\n",
    "        \n",
    "        # 1. ຄົ້ນຫາເອກະສານທີ່ກ່ຽວຂ້ອງ\n",
    "        search_results = DocumentLoader.search_similar_documents(\n",
    "            vector_store=vector_store,\n",
    "            query=query,\n",
    "            k=k\n",
    "        )\n",
    "        \n",
    "        if not search_results:\n",
    "            return {\n",
    "                \"answer\": \"❌ ບໍ່ພົບເອກະສານທີ່ກ່ຽວຂ້ອງກັບຄຳຖາມຂອງທ່ານ\",\n",
    "                \"context\": \"\",\n",
    "                \"sources\": []\n",
    "            }\n",
    "        \n",
    "        # 2. ສ້າງ context ຈາກຜົນການຄົ້ນຫາ\n",
    "        context = self.create_context_from_documents(search_results)\n",
    "        \n",
    "        # 3. ສ້າງຄຳຕອບດ້ວຍ LLM\n",
    "        print(\"🧠 Generating answer with Groq LLM...\")\n",
    "        answer = self.generate_answer(query, context)\n",
    "        \n",
    "        # 4. ສ້າງລາຍຊື່ແຫຼ່ງຂໍ້ມູນ\n",
    "        sources = []\n",
    "        for doc, score in search_results:\n",
    "            similarity = 1 - score\n",
    "            sources.append({\n",
    "                \"source_file\": doc.metadata.get('source_file', 'Unknown'),\n",
    "                \"page\": doc.metadata.get('page', 'Unknown'),\n",
    "                \"similarity\": f\"{similarity:.3f}\",\n",
    "                \"content_preview\": doc.page_content\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"context\": context,\n",
    "            \"sources\": sources\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    ຟັງຊັ່ນຫຼັກສຳລັບການທົດສອບລະບົບ RAG ກັບ Groq\n",
    "    \"\"\"\n",
    "    \n",
    "    # ການຕັ້ງຄ່າ\n",
    "    GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")  # ແທນຄ່າດ້ວຍ API key ຈິງ\n",
    "    \n",
    "    # ລາຍຊື່ໄຟລ໌ PDF (ຖ້າຕ້ອງການສ້າງ vector store ໃໝ່)\n",
    "    pdf_files = [ \n",
    "        \"C:/Users/Dell/Desktop/FINAL_2024.pdf\"\n",
    "    ]\n",
    "    \n",
    "    # ກວດສອບວ່າມີ vector store ຢູ່ແລ້ວຫຼືບໍ່\n",
    "    \n",
    "    display(Markdown(\"## 🔍 ກວດສອບ Vector Store\")) \n",
    "    loaded_vectorstore = DocumentLoader.load_existing_vector_store(\n",
    "        embedding_model=\"D:/model/BAAI-bge-m3\", \n",
    "        collection_name=\"pdf_documents\", \n",
    "        persist_directory=\"./chroma_db\"\n",
    "    )\n",
    "    \n",
    "    # ຖ້າບໍ່ມີ vector store, ສ້າງໃໝ່\n",
    "    if loaded_vectorstore is None:\n",
    "        display(Markdown(\"## 📚 Creating new vector store...\"))  \n",
    "        \n",
    "        # 1. ໂຫຼດເອກະສານ\n",
    "        documents = DocumentLoader.load_docs(pdf_files) \n",
    "        \n",
    "        if not documents:\n",
    "            print(\"❌ No documents found. Please check your PDF file paths.\")\n",
    "            return\n",
    "            \n",
    "        # 2. ເຮັດ chunking ຂໍ້ມູນ \n",
    "        display(Markdown(\"## ✂️ Chunking documents...\")) \n",
    "        # ເຮັດ chunking ຂໍ້ມູນ\n",
    "        # ໃຊ້ Model ຂອງ BAAI-bge-m3 ເພື່ອຮັບຄ່າການເຮັດ chunking ຂໍ້ມູນ ເຊີ່ງຜູ້ໃຊ້ແມ່ນສາມາດເລືອກໄດ້ຕາມໃຈເລີຍວ່າຈະ ໃຊ້ Model ຍັງໃນການເຮັດ Embedding ສາມາດໂຫລດຜ່ານ Hugginface ໄດ້ ໂດຍກຳນົດ path ເອງ ສາມາດ ເຂົ້າໄປໃນ Folder Download Model/download-model.ipynb ເພື່ອດາວໂຫລດ Model ຍັງ\n",
    "        # ກຳນັດຄ່າຕ່າງໆຂອງ chunking ໂດຍ Base on ຈາກເອກະສານ ຖ້າ ມີເອກະສານຫລາຍຫນ້າ ແນະນຳໃຫ້ລອງເພິ່ມຄ່າ chunk_size ແລະ chunk_overlap ເພື່ອຮັບຄ່າທີ່ດີກວ່າ\n",
    "        chunk_documents = DocumentLoader.chunk_documents_standard(\n",
    "            documents, \n",
    "            chunk_size=4000, \n",
    "            chunk_overlap=400, \n",
    "            tokenizer_model=\"D:/model/BAAI-bge-m3\", \n",
    "            max_token_limit=8000\n",
    "        )\n",
    "        \n",
    "        if not chunk_documents:\n",
    "            print(\"❌ Failed to chunk documents.\")\n",
    "            return\n",
    "            \n",
    "        # 3. ສ້າງ vector store \n",
    "        display(Markdown(\"## 🔄 Creating vector store...\")) \n",
    "        # ເຮັດ Embedding ຂໍ້ມູນ\n",
    "        # ກໍລະນີນີ້ຈະຖ້າດົນແນ່ ເນື່ອງຈາກວ່າ ຈະມີການເອົາ ເອກະສານທີ່ເຮົາ Chunking ມາແປງເປັນ Vector ເພື່ອບັນທືກໃນ ChromaDB ຖ້າຢາກໃຫ້ໄວ້ ໃຜມີ GPU ແນະນຳໃຫ້ໃຊ້ cuda ແທນ cpu\n",
    "        loaded_vectorstore = DocumentLoader.create_vector_store(chunk_documents)\n",
    "        \n",
    "        if loaded_vectorstore is None:\n",
    "            print(\"❌ Failed to create vector store.\")\n",
    "            return\n",
    "    \n",
    "    # ເລີ່ມຕົ້ນລະບົບ RAG ກັບ Groq \n",
    "    display(Markdown(\"## 🚀 Initializing Groq RAG System...\")) \n",
    "    \n",
    "    if GROQ_API_KEY == \"ໃສ່ Groq API Key ຂອງເຈົ້າທີ່ນີ້\":\n",
    "        print(\"❌ ກະລຸນາໃສ່ Groq API Key ຂອງເຈົ້າໃນຕົວແປ GROQ_API_KEY\")\n",
    "        print(\"💡 ສາມາດໄດ້ API key ຟຣີທີ່: https://console.groq.com\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        rag_system = GroqRAGSystem(\n",
    "            groq_api_key=GROQ_API_KEY,\n",
    "            model_name=\"meta-llama/llama-4-maverick-17b-128e-instruct\" \n",
    "        )\n",
    "        display(Markdown(\"## ✅ Groq RAG System initialized successfully !\"))  \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error initializing Groq system: {e}\")\n",
    "        return\n",
    "    \n",
    "    # ທົດສອບລະບົບດ້ວຍຄຳຖາມຕົວຢ່າງ\n",
    "    test_queries = [\n",
    "        \"RAG ກັບ Fine-tuning ມີຄວາມແຕກຕ່າງກັນແນວໃດ ?\"\n",
    "    ]\n",
    "    \n",
    "    display(Markdown(\"## 🧪 ການທົດສອບລະບົບ RAG\"))\n",
    "    display(Markdown(\"ທົດສອບດ້ວຍຄຳຖາມຕົວຢ່າງ 4 ຄຳຖາມ\"))\n",
    "    display(Markdown(\"---\"))\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n📝 ຄຳຖາມທີ່ {i}: {query}\")\n",
    "        print(\"-\" * 40)\n",
    "        display(Markdown(f\"### 📝 ຄຳຖາມທີ່ {i}: {query}\"))\n",
    "        display(Markdown(\"---\"))\n",
    "        \n",
    "        # ສົ່ງຄຳຖາມໄປລະບົບ RAG\n",
    "        result = rag_system.query_documents(\n",
    "            vector_store=loaded_vectorstore,\n",
    "            query=query,\n",
    "            k=5  # ຄົ້ນຫາ 5 ເອກະສານທີ່ກ່ຽວຂ້ອງ\n",
    "        )\n",
    "        \n",
    "        # ສະແດງຜົນລັບ\n",
    "        display(Markdown(\"#### 🤖 ຄຳຕອບ:\"))\n",
    "        display(Markdown(f\"\"\"\n",
    "            ```\n",
    "            {result['answer']}\n",
    "            ```\n",
    "        \"\"\"))\n",
    "        \n",
    "        if result['sources']:\n",
    "            display(Markdown(\"#### 📚 ແຫຼ່ງຂໍ້ມູນອ້າງອີງ:\"))\n",
    "                \n",
    "            sources_md = \"\"\n",
    "            for j, source in enumerate(result['sources'], 1):\n",
    "                    sources_md += f\"\"\"\n",
    "                **{j}.** `{source['source_file']}` (ໜ້າ {source['page']}) - ຄວາມຄ້າຍຄື: `{source['similarity']}`\n",
    "                > {source['content_preview']}...\n",
    "\n",
    "            \"\"\"\n",
    "            display(Markdown(sources_md))\n",
    "                    \n",
    "        display(Markdown(\"---\"))\n",
    "    \n",
    "    # ໂໝດ interactive ສຳລັບຜູ້ໃຊ້ສາມາດຖາມຄຳຖາມເອງ\n",
    "    display(Markdown(\"## 💬 ໂໝດ Interactive - ພິມຄຳຖາມຂອງທ່ານ (ພິມ 'quit' ເພື່ອອອກ\")) \n",
    "    display(Markdown(\"---\"))\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_query = input(\"\\n❓ ຄຳຖາມຂອງທ່ານ: \").strip()\n",
    "            \n",
    "            if user_query.lower() in ['quit', 'exit', 'ອອກ']:\n",
    "                print(\"👋 ຂອບໃຈທີ່ໃຊ້ລະບົບ RAG!\")\n",
    "                break\n",
    "                \n",
    "            if not user_query:\n",
    "                print(\"⚠️ ກະລຸນາໃສ່ຄຳຖາມ\")\n",
    "                continue\n",
    "            \n",
    "            display(Markdown(f\"### ❓ ຄຳຖາມ: `{user_query}`\"))\n",
    "            \n",
    "            # ສົ່ງຄຳຖາມໄປລະບົບ RAG\n",
    "            result = rag_system.query_documents(\n",
    "                vector_store=loaded_vectorstore,\n",
    "                query=user_query,\n",
    "                k=5\n",
    "            )\n",
    "            \n",
    "            # ສະແດງຜົນລັບ\n",
    "            display(Markdown(\"#### 🤖 ຄຳຕອບ:\"))\n",
    "            display(Markdown(f\"\"\"\n",
    "                ```\n",
    "                {result['answer']}\n",
    "                ```\n",
    "            \"\"\"))\n",
    "            \n",
    "            # ສະແດງແຫຼ່ງຂໍ້ມູນ (ແບບຫຍໍ້)\n",
    "            if result['sources']: \n",
    "                display(Markdown(\"#### 📚 ແຫຼ່ງຂໍ້ມູນອ້າງອີງ:\"))\n",
    "                for source in result['sources'][:3]:  # ສະແດງ 3 ແຫຼ່ງທຳອິດ\n",
    "                    display(Markdown(f\"#### • {source['source_file']} (ໜ້າ {source['page']})\")) \n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\n👋 ຂອບໃຈທີ່ໃຊ້ລະບົບ RAG!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"❌ ເກີດຂໍ້ຜິດພາດ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 🔍 ກວດສອບ Vector Store"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Directory not found: ./chroma_db\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## 📚 Creating new vector store..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed PDF: C:/Users/Dell/Desktop/FINAL_2024.pdf (95 pages)\n",
      "📚 Total PDF documents loaded: 95\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## ✂️ Chunking documents..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded tokenizer: D:/model/BAAI-bge-m3\n",
      "🔄 Chunking 95 documents...\n",
      "✅ Created 95 chunks\n",
      "📊 Max tokens in any chunk: 1415\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## 🔄 Creating vector store..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading embedding model: D:/model/BAAI-bge-m3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_53468\\3089190159.py:198: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded embedding model successfully\n",
      "🔄 Creating ChromaDB collection: pdf_documents\n",
      "🔄 Processing 95 documents in batches of 50\n",
      "📦 Processing batch 1/2 (50 documents)\n",
      "✅ Batch 1 completed. Total processed: 50\n",
      "📦 Processing batch 2/2 (45 documents)\n",
      "✅ Batch 2 completed. Total processed: 95\n",
      "💾 Vector store saved to: ./chroma_db\n",
      "📊 Total vectors in collection: 95\n",
      "📚 Collection name: pdf_documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_53468\\3089190159.py:261: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vector_store.persist()\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## 🚀 Initializing Groq RAG System..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## ✅ Groq RAG System initialized successfully !"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## 🧪 ການທົດສອບລະບົບ RAG"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "ທົດສອບດ້ວຍຄຳຖາມຕົວຢ່າງ 4 ຄຳຖາມ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 ຄຳຖາມທີ່ 1: RAG ກັບ Fine-tuning ມີຄວາມແຕກຕ່າງກັນແນວໃດ ?\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 📝 ຄຳຖາມທີ່ 1: RAG ກັບ Fine-tuning ມີຄວາມແຕກຕ່າງກັນແນວໃດ ?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Processing query: RAG ກັບ Fine-tuning ມີຄວາມແຕກຕ່າງກັນແນວໃດ ?\n",
      "🔍 Searching for: RAG ກັບ Fine-tuning ມີຄວາມແຕກຕ່າງກັນແນວໃດ ?\n",
      "🧠 Generating answer with Groq LLM...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### 🤖 ຄຳຕອບ:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "            ```\n",
       "            ❌ ເກີດຂໍ້ຜິດພາດໃນການສ້າງຄຳຕອບ: Error code: 413 - {'error': {'message': 'Request too large for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01jd9a4r3efedt6aj3yk87fgb0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 7899, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
       "            ```\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### 📚 ແຫຼ່ງຂໍ້ມູນອ້າງອີງ:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "                **1.** `FINAL_2024.pdf` (ໜ້າ 10) - ຄວາມຄ້າຍຄື: `-0.230`\n",
       "                > ປື້ມສັງລວມຜະລິດຕະພັນທັງໝົດຂອງ ທຄຕລ_2020_Update.2 ໜ�າທີ 7 \n",
       "     \n",
       "  \n",
       "   \n",
       " \n",
       " \n",
       "My QR \n",
       " ໃຊ�ສ�າລັບສ�າງ QRຂອງເລກບັນຊີ  ແທນການສົ່ງເລກບັນຊີ \n",
       "ໃນການໂອນເງິນໃຫ�ກັນ. ໂດຍສະແກນຜ�ານ OnePay ກ�\n",
       "ຈະສະແດງບັນຊີປາຍທາງໃຫ�ທ�ານ ເພີ່ມຄວາມສະດວກ \n",
       "ແລະ ວ�ອງໄວກວ�າ). \n",
       " \n",
       "          ອອກບັດຊິບ \n",
       " ເປັນຟັງຊັນອອກບັດຊິບ Chip Card) ກັບ BCEL One \n",
       "ແບບອອນລາຍໂດຍບ�່ຕ�ອງເຂົ້າມາ Counter. \n",
       " \n",
       "              OneX \n",
       " ເປັນຟັງຊັນ ແພລດຟອມການຄ�າອິເລັກໂທຼນີດ ທີ່ມີການຊື້ -\n",
       "ຂາຍສິນຄ�າ ແລະ ການບ�ລິການ ແລະສາມາດຂົນສົ່ງຈາກ\n",
       "ຫຼາຍບ�ລິສັດໄດ�. \n",
       " \n",
       "ສັ່ງຈອງຊື້ພັນທະບັດ \n",
       " ເປັນຟັງຊັນໃນການຈອງແລະຊື້ພັນທະບັດຂອງລັດຖະບານ \n",
       "ຕາມທີ່ມີການແຈ�ງການປະກາດຂາຍໃນແຕ�ລະໄລຍະ ໂດຍ)\n",
       "ການຊື້ແມ�ນເມື່ອຮອດເວລາກ�ານົດ ຈະມີການຈ�າຍດອກ\n",
       "ເບ�ຍ ແລະເງິນລົງທຶນໃຫ�ຕາມຈ�ານວນ%ປະກາດຂາຍ . \n",
       " \n",
       "               ຕະຫຼາດແລກປ�ຽນ \n",
       " ເປັນຟັງຊັນລະບົບແລກປ�ຽນເງິນຕາລະຫວ�າງລູກ�າ ແລະ ລູກ\n",
       "ຄ�າຜູ�ໃຊ�ບ�ລິການສາມາດກ�ານົດອັດຕາແລກປ�ຽນ ແລະ  ,\n",
       "ເລືອກວົງເງິນບົນພື້ນຖານຂອບເຂດທີ່ລະບົບໄດ�ກ�ານົດໄວ�  \n",
       " ຖ�າຫາກວ�າການແລກປ�ຽນເງິນຕາຈັບຄູ�ກັນໄດ� ຫຼື ລະບົບຈັບ\n",
       "ຄູ�ໃຫ�ຕາມຄ�າສັ່ງຜູ�ໃຊ�ບ�ລິການ ລະບົບຈະຕັດເງິນທັນທີ. \n",
       " TAP ຕັ້ງຄ�າ \n",
       " ປ�ຽນລະຫັດຜ�ານ  ປ�ຽນລະຫັດຜ�ານທີ່ໃຊ�ເຂົ້າສູ�ລະບົບ. \n",
       "ປ�ຽນ 3 ຄ�າຖາມລັບ \n",
       " ເປັນຟັງຊັນໃຫ�ລູກທີ່ຕ�ອງການປ�ຽນ3 ຄ�າຖາມລັບ. \n",
       " ຕັ້ງຄ�າລາຍນີ້ວມື \n",
       " ເປັນການຕັ້ງຄ�າເພີ່ມລາຍນິ້ວມື ສາມາດສະແກນລາຍນິ້ມມື\n",
       "ແທນການພິມລະຫັດຜ�ານຕ�າງໆ ເພື່ອ ເປີດ/ປິດ ການເຂົ້າສູ�\n",
       "ລະບົບ ແລະ ການເພີ່ມເລກບັນຊີເພື່ອໂອນເງິນດ�ວຍລາຍນິ້ວ\n",
       "ມື. \n",
       " ລັອກ/ປົດລັອກບັດ \n",
       " ສາມາດໃຊ� ເປີດ/ປິດ ການນ�າໃຊ�ບັດ ໃນກ�ລະນີບັດເສຍ, ບັດ\n",
       "ຖືກລັກ ຫຼື ຕ�ອງການລະງ�ບບັດໄວ�ຊົ່ວຄາວ. ຖ�າບັດຖືກລັອກ \n",
       "ຈະບ�່ສາມາດນ�າໃຊ�ບັດເພື່ອຖອນເງິນ ແລະ ຊ�າລະຄ�າບ�ລິການ\n",
       "ຕ�າງໆຜ�ານ BCEL One ໄດ�....\n",
       "\n",
       "            \n",
       "                **2.** `FINAL_2024.pdf` (ໜ້າ 81) - ຄວາມຄ້າຍຄື: `-0.236`\n",
       "                > ປື້ມສັງລວມຜະລິດຕະພັນທັງໝົດຂອງ ທຄຕລ_2020_Update.2 ໜ�າທີ 78 \n",
       " ໄດ�ຮັບຄະແນນສະສົມໄມລ�ເພີ່ມຕື່ມ 3% ຈາກຈ�ານວນຄະແນນທີ່ໄດ�ໃນຖ�ຽວບິນນັ້ນ ຫຼື ຄັ້ງນັ້ນຂອງທຸກໆ\n",
       "ເສັ້ນທາງບິນ ທັງເສັ້ນທາງພາຍໃນ ແລະ ຕ�າງປະເທດ. \n",
       "ສ�າຄັນ  :ກ�ລະນີທີ່ທ�ານມີທັງບັດສະມາຊິກຂອງການບິນລາວ ແລະ ບັດຮ�ວມພິເສດ Co- brand, ທ�ານສາມາດ\n",
       "ເລືອກນ�າໃຊ�ສິດທິພິເສດຈາກບັດໃດບັດໜຶ່ງເທົ່ານັ້ນ  .ບ�່ສາມາດສະເໜີທັງສອງບັດ ເພື່ອຮັບສິດທິພິເສດເປັນ 2 \n",
       "ເທົ່າ.  \n",
       "ບັດ Co- brand \n",
       "Gold Sky \n",
       " ໃຊ�ເປັນບັດສະມາຊິກສະສົມໄມລ�ເພື່ອແລກຂອງສົມມະນາຄຸນຈາກການບິນລາວ, \n",
       " ໄດ�ຮັບສ�ວນຫ�ດ 30%  ສ�າລັບຫ�ອງພັກຮັບຮອງພິເສດຈາກການບິນລາວ ສະເພາະຢູ�ສະ ໜາມບິນປາຍທາງທີ່\n",
       "ການບິນລາວມີ ແລະ ແຕ�ຜູ�ຖືບັດຕ�ອງແຈ�ງພະນັກງານການບິນລາວ ທີ່ຈຸດ Check- in ຖ�າທ�ານຕ�ອງການນ�າ\n",
       "ໃຊ�ຫ�ອງພັກຮັບຮອງພິເສດຈາກການບິນລາວ). \n",
       " ໃຊ�ສະສົມໄມລ� ເພື່ອແລກຊື້ປີ້ເຮືອບິນກັບການບິນລາວ ແລະ ຍົກລະດັບຈາກປີ້ທ�ໍາມະດາ ເປັນປີ້ບ�ອນນັ່ງ\n",
       "ທຸລະກິດ ແຕ�ຕ�ອງແຈ�ງໃຫ�ພະນັກງານ ການບິນລາວຮັບຮູ� 24 ຊົ່ວໂມງກ�ອນການເດີນທາງ). \n",
       " ໃຊ�ສະສົມໄມລ� ເພື່ອແລກຊື້ປີ້ເຮືອບິນກັບການບິນໃຫ�ແກ�ຕົນເອງ, ຄອບຄົວ ຫຼື ໝູ�ເພື່ອນ. \n",
       " ໄດ�ຮັບຄະແນນສະສົມໄມລ�ເພີ່ມຕື່ມ 2% ຈາກຈ�ານວນຄະແນນທີ່ໄດ�ໃນຖ�ຽວບິນນັ້ນ ຫຼື ຄັ້ງນັ້ນຂອງທຸກໆ\n",
       "ເສັ້ນທາງບິນ ທັງເສັ້ນທາງພາຍໃນ ແລະ ຕ�າງປະເທດ. \n",
       " ໄດ�ຮັບສິດອັນດັບທີ 2 ໃນການໄດ�ບ�ອນກ�ອນ ກ�ລະນີລ�ຖ�າ Stand by list \n",
       " ໄດ�ຮັບສ�ວນຫ�ດເມື່ອເຂົ້າພັກທີ່ໂຮງແຮມເມືອງທອງ ແຂວງ ຫຼວງພະບາງ ອີງຕາມໂປຼໂມຊັ້ນທີ່ໂຮງແຮມ\n",
       "ອອກແຕ�ລະໄລຍະ \n",
       " ສາມາດແຈ�ງປີ້ເຮືອບິນທີ່ປ�ອງບ�ລິການແຈ�ງປີ້ຂອງຊັ້ນທຸລະກິດໄດ� Business Check- in Counter) \n",
       " ໄດ�ຮັບນະໂຍບາຍນ�້າໜັກເກີນ 8 Kg, ສິດນີ້ບ�່ສາມາດໃຊ�ໄດ�ກັບສາຍການບິນອື່ນ Code Share Flight) \n",
       " ໄດ�ຮັບສິດພິເສດອັນດັບທີ່ 2 ໃນການຂຶ້ນເຮືອບິນກ�ອນເວລາ Boarding \n",
       " ສາມາດເຂົ້າໃຊ�ບ�ລິການທີ່ປ�ອງຈອງ-ຂາຍປີ້ການບິນລາວໂດຍບ�່ຕ�ອງກົດບັດຄິວ \n",
       " ສ�າຄັນ:  ກ�ລະນີທີ່ທ�ານມີທັງບັດສະມາຊິກຂອງການບິນລາວ ແລະ ບັດຮ�ວມພິເສດ Co- brand, ທ�ານ\n",
       "ສາມາດເລືອກນ�າໃຊ�ສິດທິພິເສດຈາກບັດໃດບັດໜຶ່ງເທົ່ານັ້ນ. ບ�່ສາມາດສະເໜີທັງສອງບັດ ເພື່ອຮັບສິດທິ\n",
       "ພິເສດເປັນ 2 ເທົ່າ.   \n",
       " \n",
       " \n",
       "ບັດ Co- brand \n",
       "Silver Cloud \n",
       " ໃຊ�ເປັນບັດສະມາຊິກສະສົມໄມລ�ເພື່ອແລກຂອງສົມມະນາຄຸນຈາກການບິນລາວ \n",
       " ໄດ�ຮັບສ�ວນຫ�ດ 20%  ສ�າລັບຫ�ອງພັກຮັບຮອງພິເສດຈາກການບິນລາວ ສະເພາະຢູ�ສະໝາມບິນໝາຍ\n",
       "ປາຍທາງທີ່ການບິນລາວມີ ແລະ ແຕ�ຜູ�ຖືບັດຕ�ອງແຈ�ງພະນັກງານການບິນລາວ ທີ່ຈຸດ Check- in ຖ�າທ�ານ\n",
       "ຕ�ອງການນ�າໃຊ�ຫ�ອງພັກຮັບຮອງພິເສດຈາກການບິນລາວ). \n",
       " ໃຊ�ສະສົມໄມລ� ເພື່ອແລກຊື້ປີ້ເຮືອບິນກັບການບິນໃຫ�ແກ�ຕົນເອງ, ຄອຍຄົວ, ຫຼື ໝູ�ເພື່ອນ. \n",
       " ໄດ�ຮັບສິດອັນດັບທີ 3 ໃນການໄດ�ບ�ອນກ�ອນ ກ�ລະນີລ�ຖ�າ Stand by list \n",
       " ໄດ�ຮັບຄະແນນສະສົມໄມລ�ເພີ່ມຕື່ມ 1% ຈາກຈ�ານວນຄະແນນທີ່ໄດ�ໃນຖ�ຽວບິນນັ້ນ ຫຼື ຄັ້ງນັ້ນຂອງທຸກໆ\n",
       "ເສັ້ນທາງບິນ ທັງເສັ້ນທາງພາຍໃນ ແລະ ຕ�າງປະເທດ. \n",
       " ໄດ�ຮັບສ�ວນຫ�ດເມື່ອເຂົ້າພັກທີ່ໂຮງແຮມເມືອງທອງ ແຂວງ ຫຼວງພະບາງ ອີງຕາມໂປຼໂມຊັ້ນທີ່ໂຮງແຮມ\n",
       "ອອກແຕ�ລະໄລຍະ \n",
       " ໄດ�ຮັບນະໂຍບາຍນ�້າໜັກເກີນ 5 Kg, ສິດນີ້ບ�່ສາມາດໃຊ�ໄດ�ກັບສາຍການບິນອື່ນ Code Share Flight) \n",
       " ສ�າຄັນ:  ກ�ລະນີທີ່ທ�ານມີທັງບັດສະມາຊິກຂອງການບິນລາວ ແລະ ບັດຮ�ວມພິເສດ Co- brand, ທ�ານ\n",
       "ສາມາດເລືອກນ�າໃຊ�ສິດທິພິເສດຈາກບັດໃດບັດໜຶ່ງເທົ່ານັ້ນ. ບ�່ສາມາດສະເໜີທັງສອງບັດ ເພື່ອຮັບສິດທິ\n",
       "ພິເສດເປັນ 2 ເທົ່າ. \n",
       "ສິດທິປະໂຫຍດ 1. ປະກັນໄພທ�ອງທ�ຽວໃນເວລາເດີນທາງໄປຕ�າງປະເທດ Oversea Travel Insurance) *ສ�າລັບບັດ    \n",
       "Co- Brand Platinum ແລະ ບັດ Co- Brand Gold ມີປະກັນໄພ)...\n",
       "\n",
       "            \n",
       "                **3.** `FINAL_2024.pdf` (ໜ້າ 52) - ຄວາມຄ້າຍຄື: `-0.264`\n",
       "                > ປື້ມສັງລວມຜະລິດຕະພັນທັງໝົດຂອງ ທຄຕລ_2020_Update.2 ໜ�າທີ 49 \n",
       " ທະນາຄານຈະບ�່ໃຫ�ບ�ລິການສົ່ງເງິນ  MoneyGram ໃນກ�ລະນີທີ່ຂ�້ມູນຜູ�ຮັບເງິນຢູ�ໃນລາຍຊື່ຕ�ອງຫ�າມ \n",
       "ແລະ ລະບົບ AgentConnect ບ�່ອະນຸຍາດ. \n",
       " ຊ�ວງເວລາຮັບເງິນໂອນ ຈະຂຶ້ນຢູ�ກັບເວລາການໃຫ�ບ�ລິການຂອງຕົວແທນ MoneyGram  ທີ່ປາຍທາງ. \n",
       " \n",
       "5.5 ຜະລິດຕະພັນໂອນເງິນດ�ວນ ລະຫວ�າງປະເທດ SpeedSend \n",
       " \n",
       "ຜະລິດຕະພັນໂອນເງິນດ�ວນ ລະຫວ�າງປະເທດ SpeedSend \n",
       "ຄຸນລັກສະນະ \n",
       "ເປັນຜະລິດຕະພັນໂອນເງິນດ�ວນລະຫວ�າງປະເທດ ຫຼື ເອີ້ນວ�າ SpeedSend ທີ່ສາມາດຕອບສະໜອງ \n",
       "ແລະ ເປັນທາງເລືອກໃຫ�ແກ�ກຸ�ມລູກຄ�າຜູ�ທີ່ມີຄວາມຕ�ອງການໃນການໂອນເງິນໄປຕ�າງປະເທດ ເຊັ່ນ:  \n",
       " ແຮງງານຕ�າງປະເທດມາເຮັດວຽກໃນ ສປປ ລາວ ໂອນເງິນກັບບ�ານໃຫ�ຄອບຄົວຢູ�ຕ�າງປະເທດ ຫຼື ບັນດາ\n",
       "ແຮງງານລາວທີ່ໄປເຮັດວຽກຢູ�ຕ�າງປະເທດໂອນເງິນກັບບ�ານໃຫ�ຄອບຄົວຢູ�ລາວ, \n",
       " ເປັນອີກໜຶ່ງຊ�ອງທາງທີ່ອ�ານວຍຄວາມສະດວກໃຫ�ແກ�ພ�່ແມ�ຜູ�ປົກຄອງ ສາມາດສົ່ງເງິນໃຫ�ຄອບຄົວ ຫຼື \n",
       "ລູກຫຼານທີ່ສຶກສາຕ�່ຢູ�ຕ�າງປະເທດ.  \n",
       "ຜົນປະໂຫຍດທີ່\n",
       "ໄດ�ຮັບ \n",
       " ເປັນການຫ�ດຜ�ອນຄ�າໃຊ�ຈ�າຍທີ່ຕ�ອງຈ�າຍໃຫ�ມືກາງ ຫຼື ຕະຫຼາດມືດ ທີ່ເອົາປຽບຜູ�ໂອນເງິນ. \n",
       " ສະດວກສະບາຍດ�ານເອກະສານ ແລະ ຂັ້ນຕອນໃນການໂອນເງິນ ແລະ ຮັບເງິນ ພ�ອມດ�ວຍຄ�າທ�ານຽມ\n",
       "ການບ�ລິການ ທີ່ແທດເໝາະ ແລະ ສາມາດຈ�າຍໄດ�.  \n",
       " ສາມາດໂອນ-ຮັບເງິນໄດ�ກັບປະເທດພະມ�າ. \n",
       " ທຄຕລ ຍິນດີຊ�ວຍທ�ານໃນການແລກປ�ຽນເງິນຕາຕ�າງປະເທດໃນແຕ�ລະໄລຍະໃນການສົ່ງ-ຮັບ. \n",
       "ເງື່ອນໄຂການໃຊ�\n",
       "ບ�ລິການ \n",
       " ສ�າລັບບຸກຄົນທີ່ເປັນຄົນຕ�າງປະເທດ: ຕ�ອງມີໜັງສືເດີນທາງພ�ອມກັບວີຊ�າເຂົ້າປະເທດລາວຍັງບ�່ໝົດ\n",
       "ກ�ານົດ. \n",
       " ສ�າລັບບຸກຄົນທີ່ເປັນຄົນລາວ ແລະ ຊາວຕ�າງດ�າວ: ຕ�ອງມີບັດປະຈ�າຕົວ, ໜັງສືຜ�ານແດນ Passport) \n",
       "ຫຼື ສ�າມະໂນຄົວ ທີ່ມີອາຍຸການນ�າໃຊ�ໄດ�ຕາມກົດໝາຍ),  \n",
       "  ສົ່ງ-ຮັບເງິນຢູ� ທຄຕລ ເປັນສະກຸນໂດລາສະຫະລັດ ເທົ່ານັ້ນ ການ ສົ່ງ-ຮັບເງິນແມ�ນຂຶ້ນກັບນະໂຍບາຍ, \n",
       "ລະບຽບຂອງປະເທດນັ້ນໆ)  \n",
       "ຂ�້ມູນເພີ່ມຕື່ມ  ຂ�້ມູນເພີ່ມເຕີມກະລຸນາເຂົ້າທີ່ www.cimb.com.my/ en/ personal/ day- to- day-\n",
       "banking/ remittance/ speedsend.html ໂທ :021 263510 \n",
       "5.6 ບ�ລິການໂອນເງິນອອກ Outward Remittance ຜ�ານລະບົບ Border Trade E-Bank) \n",
       "ບ�ລິການໂອນເງິນອອກ -  Outward Remittance (ຜ�ານລະບົບ Border Trade E-Bank) \n",
       "ຄຸນລັກສະນະ \n",
       " ທຄຕລ ສາມາດໃຫ�ບ�ລິການທ�ານທີ່ຕ�ອງການໂອນເງິນ ສະກຸນເງິນຢວນ ໄປ ສ.ປ ຈີນ ເພື່ືອຊ�າລະຄ�າສິນຄ�າ , \n",
       "ຄ�າບ�ລິການ, ຄ�າຮຽນ ແລະ ອື່ນໆ ດ�ວຍຄວາມປອດໄພ, ວ�ອງໄວ ໂດຍຜ�ານລະບົບ Border Trade E-bank \n",
       "ເຊິ່ງເປັນລະບົບສະເພາະ ການໂອນສະກຸນເງິນຢວນໄປ ສປ ຈີນ. \n",
       "ຈຸດປະສົງ ການ\n",
       "ໂອນເງິນໄປຕ�າງ\n",
       "ປະເທດ \n",
       " ສາມາດຊ�າລະຄ�າສິນຄ�າ ແລະ ບ�ລິການຕ�າງໆ. \n",
       " ສ�າລັບລູກຄ�າສ�ວນບຸກຄົນທ�ານສາມາດໂອນເງິນໄປຕ�າງປະເທດເພື່ອຊ�າລະ ຄ�າປິ່ນປົວ,  ການສຶກສາ, \n",
       "ຢ�ຽມຢາມຕ�າງປະເທດ ຕາມລະບຽບການທີ່ທະຄານແຫ�ງ ສປປລາວ ວາງອອກແຕ�ລະໄລຍະ. \n",
       "ຜົນປະໂຫຍດ \n",
       "ທີ່ໄດ�ຮັບ \n",
       "  ສາມາດໂອນເງິນໄປທຸກທະນາຄານທີ່ຢູ�ໃນ ສ.ປ ຈີນ ດ�ວຍຄວາມວອ�ງໄວ ແລະ ປອດໄພ. \n",
       " ສາມາດໂອນອອກໄດ�ສະເພາະສະກຸນເງິນຢວນ CNY)...\n",
       "\n",
       "            \n",
       "                **4.** `FINAL_2024.pdf` (ໜ້າ 69) - ຄວາມຄ້າຍຄື: `-0.281`\n",
       "                > ປື້ມສັງລວມຜະລິດຕະພັນທັງໝົດຂອງ ທຄຕລ_2020_Update.2 ໜ�າທີ 66 \n",
       "ໝາຍເຫດ ອັດຕາດອກເບ�ຍ ແລະ ຄ�າທ�ານຽມ ອາດຈະປ�ຽນຕາມການປະກາດໃຊ�ໃນແຕ�ລະໄລຍະ \n",
       " \n",
       "9.6 ໜັງສືຄ�້າປະກັນການຈ�າຍເງິນ )Payment Guarantees) \n",
       "ໜັງສືຄ�້າປະກັນການຈ�າຍເງິນ (Payment Guarantees) \n",
       "ຄຸນລັກສະນະ  ເພື່ອຄ�້າປະກັນພັນທະການຈ�າຍເງິນຂອງຜູ�ສະເໜີ ຜູ�ຊື້). ກ�ລະນີຜູ�ສະເໜີບ�່ຊ�າລະສິນຄ�າ, ຜູ�ຮັບຜົນ\n",
       "ປະໂຫຍດ ຜູ�ຂາຍ) ຈິ່ງຮຽກຮ�ອງໃຫ�ທະນາຄານຊ�າລະຄ�າສິນຄ�າແທນ. \n",
       "ຄຸນສົມບັດຂອງ\n",
       "ຜູ�ສະເໜີ \n",
       " ມີບັນຊີນ�າ ທຄຕລ \n",
       " ໃບທະບຽນວິສາຫະກິດ  \n",
       "ເອກະສານ\n",
       "ປະກອບຫຼັກ \n",
       " ສັນຍາ \n",
       " ເອກະສານອື່ນໆຕາມແບບຟອມ ຂອງ ທຄຕລ \n",
       "ວົງເງິນໜັງສືຄ�້າ\n",
       "ປະກັນ \n",
       " ຂື້ນກັບແຕ�ລະໂຄງການ \n",
       "ອັດຕາດອກເບ�ຍ \n",
       ")ຕ�່ປີ  \n",
       " ບ�່ມີ \n",
       "ຄ�າທ�ານຽມ  ອີງຕາມການປະກາດໃຊ�ໃນແຕ�ລະໄລຍະ \n",
       "ໄລຍະເວລາ  ອີງຕາມແຕ�ລະໂຄງການ \n",
       "ຫຼັກຊັບຄ�້າປະກັນ  ບັນຊີເງິນຝາກປະຢັດ, ບັນຊີເງິນຝາກກະແສລາຍວັນ, ບັນຊີເງິນຝາກມີກ�ານົດ, ວົງເງິນສິນເຊື່ອ, \n",
       "ທະນາຄານອື່ນ. \n",
       "ໝາຍເຫດ ອັດຕາດອກເບ�ຍ ແລະ ຄ�າທ�ານຽມ ອາດຈະປ�ຽນຕາມການປະກາດໃຊ�ໃນແຕ�ລະໄລຍະ \n",
       " \n",
       "9.7 ໜັງສືຄ�້າປະກັນເພື່ອເອົາສິນຄ�າອອກຈາກທ�າເຮືອ )Trade Finance) \n",
       "ໜັງສືຄ�້າປະກັນເພື່ອເອົາສິນຄ�າອອກຈາກທ�າເຮືອ (Shipping Guarantee) \n",
       "ຄຸນລັກສະນະ  ເພື່ອເພື່ອຄ�້າປະກັນການໃຊ�ແທນເອກະສານຂົນສົ່ງຕົ້ນສະບັບ Original Bill of Lading)  \n",
       " ເພື່ອຮັບສິນຄ�າອອກຈາກທ�າເຮືອ ທັງນີ້ກ�່ເພື່ອເປັນການຫ�ດຄ�າໃຊ�ຈ�າຍໃນການເກັບຮັກສາສິນຄ�າຢູ�\n",
       "ທ�າເຮືອ. \n",
       "ຄຸນສົມບັດຂອງ\n",
       "ຜູ�ສະເໜີ \n",
       " ມີບັນຊີນ�າ ທຄຕລ \n",
       " ໃບທະບຽນວິສາຫະກິດ  \n",
       "ເອກະສານ\n",
       "ປະກອບຫຼັກ \n",
       " ເອກະສານຂົນສົ່ງ Bill of Lading)  \n",
       " ເອກະສານອື່ນໆຕາມແບບຟອມ ຂອງ ທຄຕລ \n",
       "ວົງເງິນໜັງສືຄ�້າ\n",
       "ປະກັນ \n",
       " ຂື້ນກັບມູນຄ�າສິນຄ�າ \n",
       "ອັດຕາດອກເບ�ຍ \n",
       ")ຕ�່ປີ  \n",
       " ບ�່ມີ \n",
       "ຄ�າທ�ານຽມ  ອີງຕາມການປະກາດໃຊ�ໃນແຕ�ລະໄລຍະ \n",
       "ໄລຍະເວລາ  ອີງຕາມແຕ�ລະໂຄງການ \n",
       "ຫຼັກຊັບຄ�້າປະກັນ  ບັນຊີເງິນຝາກປະຢັດ, ບັນຊີເງິນຝາກກະແສລາຍວັນ, ບັນຊີເງິນຝາກມີກ�ານົດ, ວົງເງິນສິນເຊື່ອ, \n",
       "ທະນາຄານອື່ນ. \n",
       "ໝາຍເຫດ ອັດຕາດອກເບ�ຍ ແລະ ຄ�າທ�ານຽມ ອາດຈະປ�ຽນຕາມການປະກາດໃຊ�ໃນແຕ�ລະໄລຍະ...\n",
       "\n",
       "            \n",
       "                **5.** `FINAL_2024.pdf` (ໜ້າ 85) - ຄວາມຄ້າຍຄື: `-0.283`\n",
       "                > ປື້ມສັງລວມຜະລິດຕະພັນທັງໝົດຂອງ ທຄຕລ_2020_Update.2 ໜ�າທີ 82 \n",
       " ທ�ານສາມາດຕິດຕາມລາຍການເຄື່ອນໄຫວ ແລະ ຄວມຄຸມການນ�າໃຊ�ບັດເຄຼດິດຂອງທ�ານຜ�ານ BCEL \n",
       "One, ເຊິ່ງເປັນເຄື່ອງມືທີ່ຈະຊ�ວຍໃຫ�ທ�ານນ�າໃຊ�ບັດເຄຼດິດຂອງທ�ານໄດ�ຢ�າງສະດວກສະບາຍ ແລະ ປອດ\n",
       "ໄພຍິ່ງຂຶ້ນ. ສາມາດຊ�າລະຜ�ານຫຼາຍຊ�ອງທາງເຊັ່ນ: ການສັ່ງຊື້ຜ�ານເວັບໄຊ, ອີເມວ ຫຼື ໂທລະສັບ. \n",
       "ເງື່ອນໄຂ \n",
       "ການນ�າໃຊ� \n",
       "1. ບຸກຄົນສັນຊາດລາວ ຫຼື ຕ�າງປະເທດ \n",
       "2. ເປັນບຸກຄົນທີ່ມີລາຍຮັບໝັ້ນຄົງ \n",
       "3. ມີທີ່ຢູ�ແນ�ນອນ, ຖ�າເປັນຄົນຕ�າງປະເທດຕ�ອງມີໃບອະນຸຍາດ ຫຼື ການຄ�້າປະກັນຈາກອົງການທີ່ກ�ຽວຂ�ອງ \n",
       "4. ມີວົງເງິນຄ�້າປະກັນ ສ�າລັບການຄ�າດ�ວຍເງິນໂດລາແມ�ນໄດ�ວົງເງິນໃນບັດບ�່ເກີນ 85 % ຂອງວົງເງິນ   \n",
       "ຄ�້າປະກັນ, ສ�ວນການຄ�້າປະກັນດ�ວຍສະກຸນອື່ນທີ່ບ�່ແມ�ນໂດລາ ແມ�ນໄດ�ວົງເງິນບ�່ເກີນ 80% ) \n",
       "5. ຖ�າບ�່ຕ�ອງການນ�າໃຊ�ວົງເງິນຄ�້າປະກັນ ແມ�ນສາມາດສະເໜີອອກບັດເຄຼດິດທີ່ບ�່ມີຫຼັກຊັບຄ�້າປະກັນ ໂດຍ\n",
       "ສະເໜີຜ�ານຄະນະກ�າມະການສິນເຊື່ອຕາມລະບຽບການ \n",
       "6. ມີຄວາມສາມາດທາງດ�ານການປະພຶດຕ�່ໜ�າກົດໝາຍໃນການປະຕິບັດສັນຍາ ແລະ ເງື່ອນໄຂຕ�າງໆ \n",
       "7. ຕ�ອງມີບັນຊີກັບ ທະນາຄານການຄ�າຕ�າງປະເທດລາວ ມະຫາຊົນ ຢ�າງໜ�ອຍ 1 ບັນຊີ, ມີບັດປະຈ�າຕົວ ຫຼື \n",
       "ໜັງສືເດີນທາງ passport) ທີ່ບ�່ໝົດອາຍຸ ຫຼື ປື້ມສ�າມະໂນຄົວ \n",
       "ໝາຍເຫດ \n",
       " ອີງຕາມລະບຽບຂອງ ທຄຕລ, ແຕ�ລະບັດມີການກ�ານົດວົງເງິນການຖອນເງິນສົດ ແລະ ການໃຊ�ຈ�າຍຕ�່ຄັ້ງ\n",
       "ຕ�່ວັນ. ຕາຕະລາງກ�ຽວກັບວົງເງິນການວົງເງິນການຖອນ, ການໃຊ�ຈ�າຍ ແລະ ຄ�າແນະນ�າການນ�າໃຊ� ແມ�ນ\n",
       "ລະບຸລະອຽດຢູ�ໃນໃບເງື່ອນໄຂທີ່ທາງທະນາຄານມອບໃຫ�ແກ�ທ�ານເພື່ອເປັນບ�ອນອີງໃນການນ�າໃຊ�. \n",
       "ສະນັ້ນ, ຜູ�ຖືບັດຄວນສຶກສາເງື່ອນໄຂໃຫ�ລະອຽດເພື່ອຄວາມເຂົ້າໃຈ ແລະ ສະດວກໃນການນ�າໃຊ�ບັດ \n",
       " ແຕ�ລະປະເພດບັດ ສາມາດຖອນເງິນສົດ ຫຼື ສາມາດໃຊ�ຈ�າຍໄດ�ທັງໝົດ 100% ຂອງວົງເງິນສິນເຊື່ອ.   \n",
       "ສິດທິປະໂຫຍດ \n",
       "1. ຟຣີປະກັນໄພທ�ອງທ�ຽວໃນເວລາເດີນທາງໄປຕ�າງປະເທດ Oversea Travel Insurance) \n",
       "ທຸກຄັ້້ງທີ່ທ�ານເດີນທາງໄປຕ�າງປະເທດ ແລະ ນ�າໃຊ�ບັດ BCEL World Mastercard ຂອງທ�ານຊ�າລະ\n",
       "ຄ�າເດີນທາງ ປີ້ຍົນ) , ທ�ານຈະໄດ�ຮັບການຄຸ�ມຄອງຈາກແຜນປະກັນໄພທ�ອງທ�ຽວ ໃນຕະຫຼອດການ\n",
       "ເດີນທາງ ເປັນຕົ້ນ:  \n",
       "• ຄ�າໃຊ�ຈ�າຍປິ່ນປົວສຸກເສີນ     ສູງສຸດ 100.000 ໂດລາ \n",
       "• ຄ�າໃຊ�ຈ�າຍໃນການອົບພະຍົບ/ການຍ�າຍກັບຄືນຖິ່ນ ສູງສຸດ 1.000.000 ໂດລາ \n",
       "• ຄ�າອຸບັດຕິເຫດບຸກຄົນ-ຕະຫຼອດການເດີນທາງ ສູງສຸດ 85.000 ໂດລາ \n",
       "• ຄ�າເຂົ້າພັກຮັກສາທີ່ໂຮງໝ�    50 ໂດລາ/ວັນ ສູງສຸດເຖິງ 30 ວັນ \n",
       "• ຄ�າຊົດເຊີຍກ�ລະນີກະເປົາເດີນທາງເສຍຫາຍ  ສູງສຸດ 1.500 ໂດລາ \n",
       "• ຄ�າຊົດເຊີຍກ�ລະນີຖ�ຽວບິນລ�າຊ�າ   75 ໂດລາ/ຊົ່ວໂມງ \n",
       "• ກະເປົາເດີນທາງລ�າຊ�າ    75 ໂດລາ/ຊົ່ວໂມງ \n",
       "ແລະ ລາຍລະອຽດອື່ນໆສາມາດເບິ່ງເພີ່ມເຕີມໄດ�ຈາກເງື່ອນໄຂການຄຸ�ມຄອງປະກັນໄພ.  \n",
       "• ຄຸ�ມຄອງກ�ລະນີທີ່ທ�ານນ�າໃຊ�ບັດຊ�າລະຄ�າສິນຄ�າ ແຕ�ບ�່ໄດ�ຮັບເຄື່ອງ ຫຼື ເຄື່ອງທີ່ໄດ�ຮັບບ�່ຖືກຕ�ອງ\n",
       "ຕາມລາຍການທີ່ຕ�ອງການ ຫຼື ນ�າໃຊ�ບ�່ໄດ�ເນື່ອງຈາກເປ�ເພເສຍຫາຍ ສູງສຸດ 1.500 ໂດລາ. \n",
       " \n",
       "2. ການລົງທະບຽນນ�າໃຊ�ຫ�ອງພັກຮັບຮອງ LoungeKey \n",
       "BCEL World Mastercard ໄດ�ຮັບສິດເຂົ້າຫ�ອງພັກຮັບຮອງຂອງສະໜາມບິນຊັ້ນນ�າຕ�າງໆຟຣິ 2 ຄັ້ງ/\n",
       "ປີ. ແຕ�ກ�ອນເຂົ້່ານ�າໃຊ�ບ�ລິການຫ�ອງພັກຮັບຮອງດັ່ງກ�າວນັ້ນ, ທ�ານຕ�ອງລົງທະບຽນຕາມຂັ້ນຕອນດັ່ງລຸ�ມນີ້:  \n",
       "• ດາວໂຫຼດ Mastercard Airport Experience App ຢູ� App Store ຫຼື Play Store ແລະ \n",
       "ລົງທະບຽນຜ�ານ App. \n",
       "• ປ�ອນເລກບັດ  ແລະ ອັກສອນແລນດອມເພື່ອຢືນຢັນ: ເພື່ອການຢືນຢັນ ແລະ ກວດສອບ, ທ�ານ\n",
       "ຕ�ອງເປີດຟັ່ງຊັ້ນອອນລາຍ ເພື່ອໃຫ�ລະບົບເຮັດລາຍການບ�ອກເງິນໄວ�ຊົ່ວຄາວ 1 ໂດລາ, ແຕ�\n",
       "ລາຍການດັ່ງກ�າວນີ້ຈະບ�່ຖືກຮຽກເກັບເຂົ້າບັດຂອງທ�ານ ແລະ ຈະຖືກປົດລ�ອກພາຍໃນ 10 ວັນ. \n",
       "• ປ�ອນຂ�້ມູນບັດ ແລະ ຕັ້ງ User: ປ�ອນຂ�້ມູນບັດໃຫ�ຖືກຕ�ອງ ເຊິ່ງຕ�ອງເປີດຟັ່ງຊັ່ນອອນລາຍໄວ�\n",
       "ກ�ອນ 1 ຄັ້ງ). ຫຼັງຈາກນັ້່ນກົດ Verify . ຈາກນັ້ນ. ປ�ອນຂ�້ມູນສ�ວນຕົວ, ຊື່ ແລະ ນາມສະກຸນ, ເບີ...\n",
       "\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## 💬 ໂໝດ Interactive - ພິມຄຳຖາມຂອງທ່ານ (ພິມ 'quit' ເພື່ອອອກ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👋 ຂອບໃຈທີ່ໃຊ້ລະບົບ RAG!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
