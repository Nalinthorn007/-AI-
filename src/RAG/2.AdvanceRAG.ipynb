{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "import os\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamlinedAdvancedRAG:\n",
    "    \"\"\"\n",
    "    Advanced RAG ‡ªÅ‡∫ö‡∫ö‡∫á‡ªà‡∫≤‡∫ç - ‡ªÅ‡∫≠‡∫±‡∫î‡ªÉ‡∫ä‡ªâ Process ‡∫ô‡∫µ‡ªâ‡ªÄ‡∫õ‡∫±‡∫ô‡∫´‡∫º‡∫±‡∫Å:\n",
    "    1. Dense Retrieval \n",
    "    2. Query Rewriting (LLM)\n",
    "    3. HyDE (LLM)\n",
    "    4. Re-ranking\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str, anthropic_api_key: str = None):\n",
    "        # ‡∫ï‡∫¥‡∫î‡∫ï‡∫±‡ªâ‡∫á‡∫û‡∫∑‡ªâ‡∫ô‡∫ñ‡∫≤‡∫ô\n",
    "        self.client = chromadb.PersistentClient(path=\"../Vector/chroma_db\")\n",
    "        self.collection = self._load_collection(collection_name)\n",
    "        \n",
    "        # Models\n",
    "        self.embedding_model = SentenceTransformer('D:/model/BAAI-bge-m3',device='cpu')\n",
    "        self.rerank_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "        \n",
    "        # LLM Setup\n",
    "        api_key = anthropic_api_key or os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise ValueError(\"‡∫Å‡∫∞‡∫•‡∫∏‡∫ô‡∫≤‡ªÉ‡∫´‡ªâ ANTHROPIC_API_KEY\")\n",
    "        \n",
    "        # Main LLM (Claude Opus 4)\n",
    "        self.llm = ChatAnthropic(\n",
    "            api_key=api_key,\n",
    "            model=\"claude-opus-4-1-20250805\",\n",
    "            temperature=0.1,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        # Query processing LLM (‡ªÉ‡∫ä‡ªâ Sonnet ‡ªÄ‡∫û‡∫∑‡ªà‡∫≠‡∫õ‡∫∞‡∫´‡∫ç‡∫±‡∫î)\n",
    "        self.query_llm = ChatAnthropic(\n",
    "            api_key=api_key,\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            temperature=0.0,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Streamlined Advanced RAG ready! ({self.collection.count()} documents)\")\n",
    "    \n",
    "    def _load_collection(self, collection_name: str):\n",
    "        \"\"\"‡ªÇ‡∫´‡∫º‡∫î collection\"\"\"\n",
    "        try:\n",
    "            return self.client.get_collection(name=collection_name)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Cannot load collection '{collection_name}': {e}\")\n",
    "    \n",
    "    # ==================== 1. QUERY REWRITING ====================\n",
    "    \n",
    "    def rewrite_query(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        ‡ªÉ‡∫ä‡ªâ LLM ‡∫õ‡∫±‡∫ö‡∫õ‡∫∏‡∫á‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°‡ªÉ‡∫´‡ªâ‡ªÄ‡ªù‡∫≤‡∫∞‡∫™‡∫ª‡∫°‡∫Å‡∫±‡∫ö‡∫Å‡∫≤‡∫ô‡∫Ñ‡∫ª‡ªâ‡∫ô‡∫´‡∫≤\n",
    "        \"\"\"\n",
    "        rewriting_prompt = f\"\"\"‡∫ó‡ªà‡∫≤‡∫ô‡ªÄ‡∫õ‡∫±‡∫ô‡∫ú‡∫π‡ªâ‡∫ä‡ªà‡∫ß‡∫ç‡ªÉ‡∫ô‡∫Å‡∫≤‡∫ô‡∫õ‡∫±‡∫ö‡∫õ‡∫∏‡∫á‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°‡∫™‡ªç‡∫≤‡∫•‡∫±‡∫ö‡∫•‡∫∞‡∫ö‡∫ª‡∫ö‡∫Ñ‡∫ª‡ªâ‡∫ô‡∫´‡∫≤‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô.\n",
    "\n",
    "‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°‡∫ï‡∫ª‡ªâ‡∫ô‡∫™‡∫∞‡∫ö‡∫±‡∫ö: \"{query}\"\n",
    "\n",
    "‡∫Å‡∫∞‡∫•‡∫∏‡∫ô‡∫≤‡∫õ‡∫±‡∫ö‡∫õ‡∫∏‡∫á‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°‡∫ô‡∫µ‡ªâ‡ªÉ‡∫´‡ªâ:\n",
    "- ‡ªÄ‡∫û‡∫µ‡ªà‡∫°‡∫Ñ‡∫ß‡∫≤‡∫°‡ªù‡∫≤‡∫ç‡ªÉ‡∫´‡ªâ‡∫à‡∫∞‡ªÅ‡∫à‡ªâ‡∫á ‡ªÅ‡∫•‡∫∞ ‡∫•‡∫∞‡∫≠‡∫Ω‡∫î\n",
    "- ‡ªÄ‡∫û‡∫µ‡ªà‡∫°‡∫Ñ‡ªç‡∫≤‡∫™‡ªç‡∫≤‡∫Ñ‡∫±‡∫ô‡∫ó‡∫µ‡ªà‡∫Å‡ªà‡∫Ω‡∫ß‡∫Ç‡ªâ‡∫≠‡∫á\n",
    "- ‡∫õ‡∫±‡∫ö‡ªÉ‡∫ä‡ªâ‡ªÇ‡∫Ñ‡∫á‡∫™‡ªâ‡∫≤‡∫á‡∫ó‡∫µ‡ªà‡ªÄ‡∫´‡∫°‡∫≤‡∫∞‡∫™‡∫ª‡∫°\n",
    "- ‡∫™‡∫±‡ªâ‡∫ô‡ªÅ‡∫•‡∫∞‡∫Å‡∫∞‡∫ä‡∫±‡∫ö\n",
    "\n",
    "‡∫ï‡∫≠‡∫ö‡ªÅ‡∫ï‡ªà‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°‡∫ó‡∫µ‡ªà‡∫õ‡∫±‡∫ö‡∫õ‡∫∏‡∫á‡ªÅ‡∫•‡ªâ‡∫ß‡ªÄ‡∫ó‡∫ª‡ªà‡∫≤‡∫ô‡∫±‡ªâ‡∫ô:\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.query_llm.invoke(rewriting_prompt)\n",
    "            rewritten = response.content.strip()\n",
    "            \n",
    "            # ‡ªÄ‡∫≠‡∫ª‡∫≤ quotes ‡∫≠‡∫≠‡∫Å‡∫ñ‡ªâ‡∫≤‡∫°‡∫µ\n",
    "            rewritten = rewritten.strip('\"\\'')\n",
    "            \n",
    "            print(f\"üîÑ Query rewritten: '{query}' ‚Üí '{rewritten}'\")\n",
    "            return rewritten\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Query rewriting failed: {e}\")\n",
    "            return query\n",
    "    \n",
    "    # ==================== 2. HyDE GENERATION ====================\n",
    "    \n",
    "    def generate_hyde(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        ‡∫™‡ªâ‡∫≤‡∫á‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô‡∫™‡∫ª‡∫°‡∫°‡∫∏‡∫î‡∫ï‡∫¥‡∫ñ‡∫≤‡∫ô‡∫î‡ªâ‡∫ß‡∫ç Claude Opus 4\n",
    "        \"\"\"\n",
    "        hyde_prompt = f\"\"\"‡∫ó‡ªà‡∫≤‡∫ô‡ªÄ‡∫õ‡∫±‡∫ô‡∫ú‡∫π‡ªâ‡∫ä‡ªà‡∫ß‡∫ç‡∫ó‡∫µ‡ªà‡∫ä‡ªà‡∫Ω‡∫ß‡∫ä‡∫≤‡∫ô‡ªÉ‡∫ô‡∫î‡ªâ‡∫≤‡∫ô‡∫Å‡∫≤‡∫ô‡∫™‡ªâ‡∫≤‡∫á‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô‡∫™‡∫ª‡∫°‡∫°‡∫∏‡∫î‡∫ï‡∫¥‡∫ñ‡∫≤‡∫ô\n",
    "\n",
    "‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°: {query}\n",
    "\n",
    "‡∫Ç‡∫Ω‡∫ô‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô:\n",
    "- ‡∫ï‡∫≠‡∫ö‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°‡ªÇ‡∫î‡∫ç‡∫Å‡∫ª‡∫á‡ªÅ‡∫•‡∫∞‡∫ä‡∫±‡∫î‡ªÄ‡∫à‡∫ô\n",
    "- ‡ªÉ‡∫ä‡ªâ‡∫û‡∫≤‡∫™‡∫≤‡ªÅ‡∫•‡∫∞‡∫Ñ‡ªç‡∫≤‡∫™‡∫±‡∫ö‡∫ó‡∫µ‡ªà‡∫°‡∫µ‡ªÇ‡∫≠‡∫Å‡∫≤‡∫î‡∫õ‡∫≤‡∫Å‡∫ª‡∫î‡ªÉ‡∫ô‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô‡∫à‡∫¥‡∫á\n",
    "- ‡∫°‡∫µ‡ªÄ‡∫ô‡∫∑‡ªâ‡∫≠‡∫´‡∫≤‡∫ó‡∫µ‡ªà‡∫°‡∫µ‡∫Ñ‡∫∏‡∫ô‡∫ô‡∫∞‡∫û‡∫≤‡∫ö‡ªÅ‡∫•‡∫∞‡∫ñ‡∫∑‡∫Å‡∫ï‡ªâ‡∫≠‡∫á\n",
    "- ‡∫ç‡∫≤‡∫ß‡∫õ‡∫∞‡∫°‡∫≤‡∫ô 100-150 ‡∫Ñ‡ªç‡∫≤\n",
    "- ‡ªÄ‡∫Ç‡∫ª‡ªâ‡∫≤‡ªÄ‡∫•‡∫∑‡ªà‡∫≠‡∫á‡ªÇ‡∫î‡∫ç‡∫Å‡∫ª‡∫á ‡∫ö‡ªç‡ªà‡∫ï‡ªâ‡∫≠‡∫á‡∫°‡∫µ‡∫ö‡∫ª‡∫î‡∫ô‡ªç‡∫≤\n",
    "\n",
    "‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.llm.invoke(hyde_prompt)\n",
    "            hyde_doc = response.content.strip()\n",
    "            \n",
    "            print(f\"üìù HyDE generated: {len(hyde_doc)} chars\")\n",
    "\n",
    "            return hyde_doc\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  HyDE generation failed: {e}\")\n",
    "            return query\n",
    "    \n",
    "    # ==================== 3. DENSE RETRIEVAL ====================\n",
    "    \n",
    "    def dense_retrieval(self, query: str, n_results: int = 10) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Dense retrieval ‡∫î‡ªâ‡∫ß‡∫ç semantic embeddings\n",
    "        \"\"\"\n",
    "        query_embedding = self.embedding_model.encode([query]).tolist()\n",
    "        \n",
    "        results = self.collection.query(\n",
    "            query_embeddings=query_embedding,\n",
    "            n_results=n_results\n",
    "        )\n",
    "        \n",
    "        docs = []\n",
    "        for i in range(len(results['documents'][0])):\n",
    "            docs.append({\n",
    "                'text': results['documents'][0][i],\n",
    "                'score': 1 - results['distances'][0][i],  # Convert distance to similarity\n",
    "                'id': results['ids'][0][i]\n",
    "            })\n",
    "        \n",
    "        return docs\n",
    "    \n",
    "    # ==================== 4. RE-RANKING ====================\n",
    "    \n",
    "    def rerank_documents(self, query: str, docs: List[Dict], top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Re-ranking ‡∫î‡ªâ‡∫ß‡∫ç cross-encoder\n",
    "        \"\"\"\n",
    "        if len(docs) <= top_k:\n",
    "            return docs\n",
    "        \n",
    "        print(f\"üîÑ Re-ranking {len(docs)} ‚Üí {top_k} documents...\")\n",
    "        \n",
    "        try:\n",
    "            # ‡∫™‡ªâ‡∫≤‡∫á query-document pairs\n",
    "            pairs = [(query, doc['text']) for doc in docs]\n",
    "            \n",
    "            # ‡∫Ñ‡∫¥‡∫î‡ªÑ‡∫•‡ªà relevance scores\n",
    "            scores = self.rerank_model.predict(pairs)\n",
    "            \n",
    "            # ‡ªÄ‡∫û‡∫µ‡ªà‡∫° rerank scores\n",
    "            for i, doc in enumerate(docs):\n",
    "                doc['rerank_score'] = float(scores[i])\n",
    "                doc['original_rank'] = i + 1\n",
    "            \n",
    "            # Sort ‡ªÇ‡∫î‡∫ç rerank score\n",
    "            reranked = sorted(docs, key=lambda x: x['rerank_score'], reverse=True)\n",
    "            \n",
    "            print(f\"‚úÖ Re-ranking completed\")\n",
    "            return reranked[:top_k]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Re-ranking failed: {e}\")\n",
    "            return docs[:top_k]\n",
    "    \n",
    "    # ==================== MAIN SEARCH PIPELINE ====================\n",
    "    \n",
    "    def search_advanced(self, query: str,\n",
    "                       n_results: int = 10, \n",
    "                       use_rewriting: bool = True,\n",
    "                       use_hyde: bool = True,\n",
    "                       use_reranking: bool = True,\n",
    "                       top_k: int = 5\n",
    "                       ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Advanced search pipeline ‡ªÅ‡∫ö‡∫ö‡∫á‡ªà‡∫≤‡∫ç\n",
    "        \"\"\"\n",
    "        print(f\"üöÄ Advanced search: '{query}'\")\n",
    "        \n",
    "        search_queries = [query]  # ‡ªÄ‡∫•‡∫µ‡ªà‡∫°‡∫î‡ªâ‡∫ß‡∫ç‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°‡∫ï‡∫ª‡ªâ‡∫ô‡∫™‡∫∞‡∫ö‡∫±‡∫ö\n",
    "\n",
    "        # 1. Query Rewriting\n",
    "        if use_rewriting:\n",
    "            rewritten = self.rewrite_query(query)\n",
    "            if rewritten != query:\n",
    "                search_queries.append(rewritten)\n",
    "        \n",
    "        # 2. HyDE\n",
    "        if use_hyde:\n",
    "            hyde_doc = self.generate_hyde(query)\n",
    "            search_queries.append(hyde_doc)\n",
    "        \n",
    "        # 3. Dense Retrieval ‡∫™‡ªç‡∫≤‡∫•‡∫±‡∫ö‡ªÅ‡∫ï‡ªà‡∫•‡∫∞ query\n",
    "        all_docs = {}\n",
    "        for i, sq in enumerate(search_queries):\n",
    "            print(f\"üîç Searching with query {i+1}/{len(search_queries)}\")\n",
    "\n",
    "            docs = self.dense_retrieval(sq, n_results)\n",
    "            \n",
    "            # ‡∫•‡∫ß‡∫°‡∫ú‡∫ª‡∫ô‡ªÑ‡∫î‡ªâ‡∫Æ‡∫±‡∫ö (‡∫ñ‡ªâ‡∫≤‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô‡∫ä‡ªâ‡ªç‡∫≤ ‡∫à‡∫∞‡∫•‡∫ß‡∫° scores)\n",
    "            for doc in docs:\n",
    "                doc_id = doc['id']\n",
    "                if doc_id in all_docs:\n",
    "                    # ‡∫•‡∫ß‡∫° scores ‡ªÅ‡∫•‡∫∞ ‡ªÄ‡∫û‡∫µ‡ªà‡∫° weight\n",
    "                    all_docs[doc_id]['score'] = max(all_docs[doc_id]['score'], doc['score'])\n",
    "                    all_docs[doc_id]['query_count'] = all_docs[doc_id].get('query_count', 1) + 1\n",
    "                else:\n",
    "                    doc['query_count'] = 1\n",
    "                    all_docs[doc_id] = doc\n",
    "        \n",
    "        # Convert to list and sort by score\n",
    "        retrieved_docs = sorted(all_docs.values(), key=lambda x: x['score'], reverse=True)\n",
    "        retrieved_docs = retrieved_docs[:n_results]\n",
    "        \n",
    "        print(f\"üìÑ Retrieved {len(retrieved_docs)} unique documents\")\n",
    "        \n",
    "        # 4. Re-ranking\n",
    "        if use_reranking and len(retrieved_docs) > 3:\n",
    "            final_docs = self.rerank_documents(query, retrieved_docs, \n",
    "                                             min(n_results, len(retrieved_docs),top_k))\n",
    "        else:\n",
    "            final_docs = retrieved_docs\n",
    "        \n",
    "        return final_docs\n",
    "    \n",
    "    # ==================== MAIN Q&A FUNCTION ====================\n",
    "    \n",
    "    def ask(self, question: str, n_results: int = 8, **kwargs) -> Dict:\n",
    "        \"\"\"\n",
    "        ‡∫ñ‡∫≤‡∫°‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°‡∫î‡ªâ‡∫ß‡∫ç Streamlined Advanced RAG\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"‚ùì ‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°: {question}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # ‡∫Ñ‡∫ª‡ªâ‡∫ô‡∫´‡∫≤‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô\n",
    "        docs = self.search_advanced(question, n_results, **kwargs)\n",
    "        \n",
    "        if not docs:\n",
    "            return {\"error\": \"‡∫ö‡ªç‡ªà‡∫û‡∫ª‡∫ö‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô‡∫ó‡∫µ‡ªà‡∫Å‡ªà‡∫Ω‡∫ß‡∫Ç‡ªâ‡∫≠‡∫á\"}\n",
    "        \n",
    "        # ‡∫™‡ªâ‡∫≤‡∫á context\n",
    "        context_parts = []\n",
    "        for i, doc in enumerate(docs, 1):\n",
    "            score_info = f\"(Score: {doc.get('rerank_score', doc['score']):.3f})\"\n",
    "            context_parts.append(f\"[Document {i}] {score_info}\\n{doc['text']}\")\n",
    "        \n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "        \n",
    "        # ‡∫™‡ªâ‡∫≤‡∫á prompt\n",
    "        prompt = f\"\"\"‡∫ó‡ªà‡∫≤‡∫ô‡ªÄ‡∫õ‡∫±‡∫ô‡∫ú‡∫π‡ªâ‡∫ä‡ªà‡∫ß‡∫ç AI ‡∫ó‡∫µ‡ªà‡∫ä‡ªà‡∫Ω‡∫ß‡∫ä‡∫≤‡∫ô‡ªÉ‡∫ô‡∫Å‡∫≤‡∫ô‡∫ï‡∫≠‡∫ö‡∫Ñ‡∫≥‡∫ñ‡∫≤‡∫°‡ªÇ‡∫î‡∫ç‡∫≠‡ªâ‡∫≤‡∫á‡∫≠‡∫µ‡∫á‡∫à‡∫≤‡∫Å‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô‡∫ó‡∫µ‡ªà‡ªÉ‡∫´‡ªâ‡∫°‡∫≤.\n",
    "\n",
    "        ‡∫Ñ‡∫≥‡ªÅ‡∫ô‡∫∞‡∫ô‡∫≥:\n",
    "        1. ‡∫ï‡∫≠‡∫ö‡∫Ñ‡∫≥‡∫ñ‡∫≤‡∫°‡ªÇ‡∫î‡∫ç‡∫≠‡ªâ‡∫≤‡∫á‡∫≠‡∫µ‡∫á‡∫à‡∫≤‡∫Å‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô‡∫ó‡∫µ‡ªà‡ªÉ‡∫´‡ªâ‡∫°‡∫≤‡ªÄ‡∫ó‡∫ª‡ªà‡∫≤‡∫ô‡∫±‡ªâ‡∫ô\n",
    "        2. ‡∫ñ‡ªâ‡∫≤‡∫ö‡ªç‡ªà‡∫û‡∫ª‡∫ö‡∫Ñ‡∫≥‡∫ï‡∫≠‡∫ö‡ªÉ‡∫ô‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô, ‡ªÉ‡∫´‡ªâ‡∫ö‡∫≠‡∫Å‡∫ß‡ªà‡∫≤‡∫ö‡ªç‡ªà‡∫û‡∫ª‡∫ö‡∫Ç‡ªç‡ªâ‡∫°‡∫π‡∫ô‡∫ó‡∫µ‡ªà‡∫Å‡ªà‡∫Ω‡∫ß‡∫Ç‡ªâ‡∫≠‡∫á\n",
    "        3. ‡∫•‡∫∞‡∫ö‡∫∏‡ªÅ‡∫´‡∫º‡ªà‡∫á‡∫Ç‡ªç‡ªâ‡∫°‡∫π‡∫ô‡∫ó‡∫µ‡ªà‡ªÉ‡∫ä‡ªâ‡ªÉ‡∫ô‡∫Å‡∫≤‡∫ô‡∫ï‡∫≠‡∫ö\n",
    "        4. ‡∫ï‡∫≠‡∫ö‡ªÄ‡∫õ‡∫±‡∫ô‡∫û‡∫≤‡∫™‡∫≤‡∫•‡∫≤‡∫ß‡ªÄ‡∫ó‡∫ª‡ªà‡∫≤‡∫ô‡∫±‡ªâ‡∫ô, ‡ªÉ‡∫´‡ªâ‡∫Ñ‡∫≥‡∫ï‡∫≠‡∫ö‡∫ó‡∫µ‡ªà‡∫ä‡∫±‡∫î‡ªÄ‡∫à‡∫ô ‡ªÅ‡∫•‡∫∞ ‡∫•‡∫∞‡∫≠‡∫Ω‡∫î\n",
    "        5. ‡∫ï‡∫≠‡∫ö‡ªÉ‡∫´‡ªâ‡ªÄ‡∫õ‡∫±‡∫ô Format markdown\n",
    "                \n",
    "        ‡∫Ç‡ªç‡ªâ‡∫°‡∫π‡∫ô‡∫≠‡ªâ‡∫≤‡∫á‡∫≠‡∫µ‡∫á:\n",
    "        {context}\n",
    "\n",
    "        ‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°: {question}\n",
    "        \"\"\"\n",
    "        \n",
    "        # ‡∫™‡ªâ‡∫≤‡∫á‡∫Ñ‡ªç‡∫≤‡∫ï‡∫≠‡∫ö\n",
    "        try:\n",
    "            response = self.llm.invoke(prompt)\n",
    "            answer = response.content.strip()\n",
    "            \n",
    "            return {\n",
    "                'question': question,\n",
    "                'answer': answer,\n",
    "                'sources': docs,\n",
    "                'metadata': {\n",
    "                    'total_sources': len(docs),\n",
    "                    'avg_score': np.mean([doc.get('rerank_score', doc['score']) for doc in docs]),\n",
    "                    'features_used': {\n",
    "                        'query_rewriting': kwargs.get('use_rewriting', True),\n",
    "                        'hyde': kwargs.get('use_hyde', True),\n",
    "                        'reranking': kwargs.get('use_reranking', True)\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"‡ªÄ‡∫Å‡∫µ‡∫î‡∫Ç‡ªç‡ªâ‡∫ú‡∫¥‡∫î‡∫û‡∫≤‡∫î‡ªÉ‡∫ô‡∫Å‡∫≤‡∫ô‡∫™‡ªâ‡∫≤‡∫á‡∫Ñ‡ªç‡∫≤‡∫ï‡∫≠‡∫ö: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== MAIN USAGE ====================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    ‡∫ï‡∫ª‡∫ß‡∫¢‡ªà‡∫≤‡∫á‡∫Å‡∫≤‡∫ô‡ªÉ‡∫ä‡ªâ‡∫á‡∫≤‡∫ô\n",
    "    \"\"\"\n",
    "    # ‡∫™‡ªâ‡∫≤‡∫á RAG system\n",
    "    rag = StreamlinedAdvancedRAG(\n",
    "        collection_name=\"pdf_documents\",\n",
    "        anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    ) \n",
    "    \n",
    "    # ‡∫ñ‡∫≤‡∫°‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°\n",
    "    result = rag.ask(\n",
    "        question=\"SMS Banking Package ‡∫™‡∫∞‡ªù‡∫±‡∫Å‡ªÅ‡∫ô‡∫ß‡ªÉ‡∫î ‡ªÅ‡∫•‡∫∞ ‡∫°‡∫µ Package ‡∫ç‡∫±‡∫á‡ªÅ‡∫ô‡ªà?\",\n",
    "        n_results=20, # ‡∫à‡∫≥‡∫ô‡∫ß‡∫ô‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô‡∫ó‡∫µ‡ªà‡∫à‡∫∞‡∫Ñ‡∫ª‡ªâ‡∫ô‡∫´‡∫≤\n",
    "        use_rewriting=True,    # ‡ªÉ‡∫ä‡ªâ LLM ‡∫õ‡∫±‡∫ö‡∫õ‡∫∏‡∫á‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°  True = ‡ªÄ‡∫õ‡∫µ‡∫î / False = ‡∫õ‡∫¥‡∫î\n",
    "        use_hyde=True,        # ‡∫ö‡ªç‡ªà‡ªÉ‡∫ä‡ªâ HyDE  True = ‡ªÄ‡∫õ‡∫µ‡∫î / False = ‡∫õ‡∫¥‡∫î\n",
    "        use_reranking=True,   # ‡∫ö‡ªç‡ªà‡ªÉ‡∫ä‡ªâ re-ranking  True = ‡ªÄ‡∫õ‡∫µ‡∫î / False = ‡∫õ‡∫¥‡∫î\n",
    "        top_k=10 # ‡∫à‡∫≥‡∫ô‡∫ß‡∫ô Ranking ‡∫ó‡∫µ‡ªà‡∫à‡∫∞‡∫Ñ‡∫ª‡ªâ‡∫ô‡∫´‡∫≤\n",
    "    )\n",
    "    \n",
    "    if 'error' not in result:\n",
    "        display(Markdown(f\"\\n‚úÖ ‡∫Ñ‡ªç‡∫≤‡∫ï‡∫≠‡∫ö: {result['answer']}\"))   \n",
    "        display(Markdown(f\"\\nüìä ‡∫Ç‡ªç‡ªâ‡∫°‡∫π‡∫ô:\")) \n",
    "        display(Markdown(f\"   Sources: {result['metadata']['total_sources']}\")) \n",
    "        display(Markdown(f\"   Avg Score: {result['metadata']['avg_score']:.3f}\")) \n",
    "        display(Markdown(f\"   Features: {result['metadata']['features_used']}\"))  \n",
    "    else:\n",
    "        print(f\"\\n‚ùå {result['error']}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Streamlined Advanced RAG ready! (95 documents)\n",
      "\n",
      "============================================================\n",
      "‚ùì ‡∫Ñ‡ªç‡∫≤‡∫ñ‡∫≤‡∫°: SMS Banking Package ‡∫™‡∫∞‡ªù‡∫±‡∫Å‡ªÅ‡∫ô‡∫ß‡ªÉ‡∫î ‡ªÅ‡∫•‡∫∞ ‡∫°‡∫µ Package ‡∫ç‡∫±‡∫á‡ªÅ‡∫ô‡ªà?\n",
      "============================================================\n",
      "üöÄ Advanced search: 'SMS Banking Package ‡∫™‡∫∞‡ªù‡∫±‡∫Å‡ªÅ‡∫ô‡∫ß‡ªÉ‡∫î ‡ªÅ‡∫•‡∫∞ ‡∫°‡∫µ Package ‡∫ç‡∫±‡∫á‡ªÅ‡∫ô‡ªà?'\n",
      "üîÑ Query rewritten: 'SMS Banking Package ‡∫™‡∫∞‡ªù‡∫±‡∫Å‡ªÅ‡∫ô‡∫ß‡ªÉ‡∫î ‡ªÅ‡∫•‡∫∞ ‡∫°‡∫µ Package ‡∫ç‡∫±‡∫á‡ªÅ‡∫ô‡ªà?' ‚Üí '‡∫ß‡∫¥‡∫ó‡∫µ‡∫™‡∫∞‡ªù‡∫±‡∫Å‡∫ô‡∫≥‡ªÉ‡∫ä‡ªâ‡∫ö‡ªç‡∫•‡∫¥‡∫Å‡∫≤‡∫ô SMS Banking ‡∫Ç‡∫≠‡∫á‡∫ó‡∫∞‡∫ô‡∫≤‡∫Ñ‡∫≤‡∫ô ‡ªÅ‡∫•‡∫∞ ‡∫°‡∫µ‡ªÅ‡∫û‡∫±‡∫Å‡ªÄ‡∫Å‡∫±‡∫î‡ªÉ‡∫î‡ªÅ‡∫î‡ªà‡∫ó‡∫µ‡ªà‡∫™‡∫≤‡∫°‡∫≤‡∫î‡ªÄ‡∫•‡∫∑‡∫≠‡∫Å‡ªÑ‡∫î‡ªâ?'\n",
      "üìù HyDE generated: 619 chars\n",
      "üîç Searching with query 1/3\n",
      "üîç Searching with query 2/3\n",
      "üîç Searching with query 3/3\n",
      "üìÑ Retrieved 20 unique documents\n",
      "üîÑ Re-ranking 20 ‚Üí 10 documents...\n",
      "‚úÖ Re-ranking completed\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "‚úÖ ‡∫Ñ‡ªç‡∫≤‡∫ï‡∫≠‡∫ö: ‡∫≠‡∫µ‡∫á‡∫ï‡∫≤‡∫°‡ªÄ‡∫≠‡∫Å‡∫∞‡∫™‡∫≤‡∫ô‡∫ó‡∫µ‡ªà‡ªÉ‡∫´‡ªâ‡∫°‡∫≤, ‡∫Ç‡ªâ‡∫≠‡∫ç‡∫Ç‡ªç‡∫ï‡∫≠‡∫ö‡∫Å‡ªà‡∫Ω‡∫ß‡∫Å‡∫±‡∫ö SMS Banking Package ‡∫î‡∫±‡ªà‡∫á‡∫ô‡∫µ‡ªâ:\n",
       "\n",
       "## ‡∫ß‡∫¥‡∫ó‡∫µ‡∫Å‡∫≤‡∫ô‡∫™‡∫∞‡ªù‡∫±‡∫Å SMS Banking Package:\n",
       "\n",
       "‡∫ó‡ªà‡∫≤‡∫ô‡∫™‡∫≤‡∫°‡∫≤‡∫î‡∫™‡∫∞‡ªù‡∫±‡∫Å Package ‡ªÄ‡∫û‡∫µ‡ªà‡∫°‡ªÑ‡∫î‡ªâ‡ªÇ‡∫î‡∫ç:\n",
       "- **‡∫û‡∫¥‡∫° B10 [‡∫ç‡∫∞‡∫´‡∫ß‡ªà‡∫≤‡∫á] <‡ªÄ‡∫•‡∫Å‡∫ö‡∫±‡∫ô‡∫ä‡∫µ> ‡ªÅ‡∫•‡ªâ‡∫ß‡∫™‡∫ª‡ªà‡∫á‡ªÄ‡∫ö‡∫µ 1444**\n",
       "\n",
       "## Package ‡∫ó‡∫µ‡ªà‡∫°‡∫µ‡ªÉ‡∫´‡ªâ‡ªÄ‡∫•‡∫∑‡∫≠‡∫Å:\n",
       "\n",
       "| ‡∫•‡∫∞‡∫´‡∫±‡∫î Package | ‡∫à‡∫≥‡∫ô‡∫ß‡∫ô‡ªÄ‡∫á‡∫¥‡∫ô (‡∫Å‡∫µ‡∫ö) | ‡∫à‡∫≥‡∫ô‡∫ß‡∫ô‡∫ß‡∫±‡∫ô‡∫ó‡∫µ‡ªà‡ªÉ‡∫ä‡ªâ‡ªÑ‡∫î‡ªâ | ‡∫à‡∫≥‡∫ô‡∫ß‡∫ô‡∫Ç‡ªç‡ªâ‡∫Ñ‡∫ß‡∫≤‡∫° |\n",
       "|--------------|----------------|-----------------|--------------|\n",
       "| **B05** | 5,000 | 365 ‡∫ß‡∫±‡∫ô | 30 ‡∫Ç‡ªç‡ªâ‡∫Ñ‡∫ß‡∫≤‡∫° |\n",
       "| **B10** | 10,000 | 365 ‡∫ß‡∫±‡∫ô | 60 ‡∫Ç‡ªç‡ªâ‡∫Ñ‡∫ß‡∫≤‡∫° |\n",
       "| **B25** | 25,000 | 365 ‡∫ß‡∫±‡∫ô | 150 ‡∫Ç‡ªç‡ªâ‡∫Ñ‡∫ß‡∫≤‡∫° |\n",
       "| **B50** | 50,000 | 365 ‡∫ß‡∫±‡∫ô | 300 ‡∫Ç‡ªç‡ªâ‡∫Ñ‡∫ß‡∫≤‡∫° |\n",
       "| **B100** | 100,000 | 365 ‡∫ß‡∫±‡∫ô | 600 ‡∫Ç‡ªç‡ªâ‡∫Ñ‡∫ß‡∫≤‡∫° |\n",
       "\n",
       "## ‡∫ü‡∫±‡∫á‡∫ä‡∫±‡∫ô‡∫≠‡∫∑‡ªà‡∫ô‡ªÜ‡∫ó‡∫µ‡ªà‡ªÄ‡∫õ‡∫±‡∫ô‡∫õ‡∫∞‡ªÇ‡∫´‡∫ç‡∫î:\n",
       "- ‡∫Å‡∫ß‡∫î Package ‡∫õ‡∫±‡∫î‡∫à‡∫∏‡∫ö‡∫±‡∫ô: ‡∫û‡∫¥‡∫° **C [‡∫ç‡∫∞‡∫´‡∫ß‡ªà‡∫≤‡∫á] <‡ªÄ‡∫•‡∫Å‡∫ö‡∫±‡∫ô‡∫ä‡∫µ>** ‡ªÅ‡∫•‡ªâ‡∫ß‡∫™‡∫ª‡ªà‡∫á‡ªÄ‡∫ö‡∫µ 1444\n",
       "- ‡∫ó‡∫∏‡∫Å Package ‡∫™‡∫≤‡∫°‡∫≤‡∫î‡ªÉ‡∫ä‡ªâ‡ªÑ‡∫î‡ªâ 365 ‡∫ß‡∫±‡∫ô (1 ‡∫õ‡∫µ‡ªÄ‡∫ï‡∫±‡∫°)\n",
       "\n",
       "**‡ªÅ‡∫´‡∫º‡ªà‡∫á‡∫Ç‡ªç‡ªâ‡∫°‡∫π‡∫ô:** Document 3 - ‡∫õ‡∫∑‡ªâ‡∫°‡∫™‡∫±‡∫á‡∫•‡∫ß‡∫°‡∫ú‡∫∞‡∫•‡∫¥‡∫î‡∫ï‡∫∞‡∫û‡∫±‡∫ô‡∫ó‡∫±‡∫á‡ªù‡∫ª‡∫î‡∫Ç‡∫≠‡∫á ‡∫ó‡∫Ñ‡∫ï‡∫•_2020_Update.2 ‡ªú‡ªâ‡∫≤‡∫ó‡∫µ 15"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "üìä ‡∫Ç‡ªç‡ªâ‡∫°‡∫π‡∫ô:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   Sources: 10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   Avg Score: 4.395"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   Features: {'query_rewriting': True, 'hyde': True, 'reranking': True}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
